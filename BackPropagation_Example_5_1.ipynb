{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제 5] MNIST training data 로부터 35% 비율로 validation data 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration]  loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2 = (784 X 100) Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3 = (100X10)  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "                        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.A3 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes])\n",
    "        self.A2 = np.zeros([1,hidden_nodes])\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def feed_forward(self):  \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )\n",
    "   \n",
    "    \n",
    "    # 정확도 측정함수 \n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                \n",
    "        #print(\"Current Accuracy = \", (len(matched_list)/(len(test_input_data))) )\n",
    "        \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "    \n",
    "    def train(self, input_data, target_data):   # input_data : 784 개, target_data : 10개\n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        # 출력층 loss 인 loss_3 구함\n",
    "        loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        # 출력층 가중치 W3, 출력층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)   \n",
    "        \n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3  \n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)   \n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    "        \n",
    "    def predict(self, input_data):        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐        \n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        predicted_num = np.argmax(A3)\n",
    "    \n",
    "        return predicted_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation 비율 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration]  loaded_data.shape =  (60000, 785)\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of original data =  0.0 , count =  5923\n",
      "[DataGeneration] unique number of original data =  1.0 , count =  6742\n",
      "[DataGeneration] unique number of original data =  2.0 , count =  5958\n",
      "[DataGeneration] unique number of original data =  3.0 , count =  6131\n",
      "[DataGeneration] unique number of original data =  4.0 , count =  5842\n",
      "[DataGeneration] unique number of original data =  5.0 , count =  5421\n",
      "[DataGeneration] unique number of original data =  6.0 , count =  5918\n",
      "[DataGeneration] unique number of original data =  7.0 , count =  6265\n",
      "[DataGeneration] unique number of original data =  8.0 , count =  5851\n",
      "[DataGeneration] unique number of original data =  9.0 , count =  5949\n",
      "[DataGeneration] unique number of original data =  0.0 , ratio =  9.87  %\n",
      "[DataGeneration] unique number of original data =  1.0 , ratio =  11.24  %\n",
      "[DataGeneration] unique number of original data =  2.0 , ratio =  9.93  %\n",
      "[DataGeneration] unique number of original data =  3.0 , ratio =  10.22  %\n",
      "[DataGeneration] unique number of original data =  4.0 , ratio =  9.74  %\n",
      "[DataGeneration] unique number of original data =  5.0 , ratio =  9.04  %\n",
      "[DataGeneration] unique number of original data =  6.0 , ratio =  9.86  %\n",
      "[DataGeneration] unique number of original data =  7.0 , ratio =  10.44  %\n",
      "[DataGeneration] unique number of original data =  8.0 , ratio =  9.75  %\n",
      "[DataGeneration] unique number of original data =  9.0 , ratio =  9.91  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of training data =  0.0 , count =  3831\n",
      "[DataGeneration] unique number of training data =  1.0 , count =  4447\n",
      "[DataGeneration] unique number of training data =  2.0 , count =  3933\n",
      "[DataGeneration] unique number of training data =  3.0 , count =  3977\n",
      "[DataGeneration] unique number of training data =  4.0 , count =  3777\n",
      "[DataGeneration] unique number of training data =  5.0 , count =  3547\n",
      "[DataGeneration] unique number of training data =  6.0 , count =  3801\n",
      "[DataGeneration] unique number of training data =  7.0 , count =  4033\n",
      "[DataGeneration] unique number of training data =  8.0 , count =  3794\n",
      "[DataGeneration] unique number of training data =  9.0 , count =  3860\n",
      "[DataGeneration] unique number of training data =  0.0 , ratio =  9.82  %\n",
      "[DataGeneration] unique number of training data =  1.0 , ratio =  11.4  %\n",
      "[DataGeneration] unique number of training data =  2.0 , ratio =  10.08  %\n",
      "[DataGeneration] unique number of training data =  3.0 , ratio =  10.2  %\n",
      "[DataGeneration] unique number of training data =  4.0 , ratio =  9.68  %\n",
      "[DataGeneration] unique number of training data =  5.0 , ratio =  9.09  %\n",
      "[DataGeneration] unique number of training data =  6.0 , ratio =  9.75  %\n",
      "[DataGeneration] unique number of training data =  7.0 , ratio =  10.34  %\n",
      "[DataGeneration] unique number of training data =  8.0 , ratio =  9.73  %\n",
      "[DataGeneration] unique number of training data =  9.0 , ratio =  9.9  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of test data =  0.0 , count =  2092\n",
      "[DataGeneration] unique number of test data =  1.0 , count =  2295\n",
      "[DataGeneration] unique number of test data =  2.0 , count =  2025\n",
      "[DataGeneration] unique number of test data =  3.0 , count =  2154\n",
      "[DataGeneration] unique number of test data =  4.0 , count =  2065\n",
      "[DataGeneration] unique number of test data =  5.0 , count =  1874\n",
      "[DataGeneration] unique number of test data =  6.0 , count =  2117\n",
      "[DataGeneration] unique number of test data =  7.0 , count =  2232\n",
      "[DataGeneration] unique number of test data =  8.0 , count =  2057\n",
      "[DataGeneration] unique number of test data =  9.0 , count =  2089\n",
      "[DataGeneration] unique number of test data =  0.0 , ratio =  9.96  %\n",
      "[DataGeneration] unique number of test data =  1.0 , ratio =  10.93  %\n",
      "[DataGeneration] unique number of test data =  2.0 , ratio =  9.64  %\n",
      "[DataGeneration] unique number of test data =  3.0 , ratio =  10.26  %\n",
      "[DataGeneration] unique number of test data =  4.0 , ratio =  9.83  %\n",
      "[DataGeneration] unique number of test data =  5.0 , ratio =  8.92  %\n",
      "[DataGeneration] unique number of test data =  6.0 , ratio =  10.08  %\n",
      "[DataGeneration] unique number of test data =  7.0 , ratio =  10.63  %\n",
      "[DataGeneration] unique number of test data =  8.0 , ratio =  9.8  %\n",
      "[DataGeneration] unique number of test data =  9.0 , ratio =  9.95  %\n",
      "=======================================================================================================\n",
      "training_data.shape =  (39000, 785)\n",
      "validation_data.shape =  (21000, 785)\n"
     ]
    }
   ],
   "source": [
    "# DataGeneration class 이용하여 training data , validation data 생성\n",
    "seperation_rate = 0.35  # training data 10 % 비율로 validation data 생성\n",
    "target_position = 0    # 정답은 첫번째 열\n",
    "\n",
    "try:\n",
    "    data_obj = DataGeneration('MNIST', './mnist_train.csv', seperation_rate, target_position)\n",
    "\n",
    "    (training_data, validation_data) = data_obj.generate()\n",
    "    \n",
    "    print(\"training_data.shape = \", training_data.shape)\n",
    "    print(\"validation_data.shape = \", validation_data.shape)\n",
    "\n",
    "except Exception as err:\n",
    "    print('Exception Occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 노드 100 개 인 경우의 MNIST 오차역전파 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  1 , step =  0 , current loss_val =  7.242415026603525\n",
      "epochs =  1 , step =  1000 , current loss_val =  1.8763465952954426\n",
      "epochs =  1 , step =  2000 , current loss_val =  0.9398190254167005\n",
      "epochs =  1 , step =  3000 , current loss_val =  1.0907050849815123\n",
      "epochs =  1 , step =  4000 , current loss_val =  3.6900854464874637\n",
      "epochs =  1 , step =  5000 , current loss_val =  1.1866118249868434\n",
      "epochs =  1 , step =  6000 , current loss_val =  0.896461385649001\n",
      "epochs =  1 , step =  7000 , current loss_val =  2.2266050599964613\n",
      "epochs =  1 , step =  8000 , current loss_val =  0.7953743493257139\n",
      "epochs =  1 , step =  9000 , current loss_val =  0.6691848177723277\n",
      "epochs =  1 , step =  10000 , current loss_val =  0.8021792395156528\n",
      "epochs =  1 , step =  11000 , current loss_val =  0.8723674484622244\n",
      "epochs =  1 , step =  12000 , current loss_val =  0.6973002746541075\n",
      "epochs =  1 , step =  13000 , current loss_val =  0.7355974873559281\n",
      "epochs =  1 , step =  14000 , current loss_val =  0.9736601870064319\n",
      "epochs =  1 , step =  15000 , current loss_val =  0.698317170247536\n",
      "epochs =  1 , step =  16000 , current loss_val =  0.7964177385838934\n",
      "epochs =  1 , step =  17000 , current loss_val =  0.7135452591917584\n",
      "epochs =  1 , step =  18000 , current loss_val =  0.679091033211304\n",
      "epochs =  1 , step =  19000 , current loss_val =  0.6873969089486945\n",
      "epochs =  1 , step =  20000 , current loss_val =  0.766540245389798\n",
      "epochs =  1 , step =  21000 , current loss_val =  0.9604660168577308\n",
      "epochs =  1 , step =  22000 , current loss_val =  0.8813789241199911\n",
      "epochs =  1 , step =  23000 , current loss_val =  0.8557245914362344\n",
      "epochs =  1 , step =  24000 , current loss_val =  4.206857615204648\n",
      "epochs =  1 , step =  25000 , current loss_val =  0.8140600828689302\n",
      "epochs =  1 , step =  26000 , current loss_val =  0.7134083935532984\n",
      "epochs =  1 , step =  27000 , current loss_val =  0.7763243753445975\n",
      "epochs =  1 , step =  28000 , current loss_val =  0.9871365342578453\n",
      "epochs =  1 , step =  29000 , current loss_val =  0.9485261918968956\n",
      "epochs =  1 , step =  30000 , current loss_val =  0.7798330016126946\n",
      "epochs =  1 , step =  31000 , current loss_val =  0.7405287129480542\n",
      "epochs =  1 , step =  32000 , current loss_val =  0.9056971315952043\n",
      "epochs =  1 , step =  33000 , current loss_val =  0.6833300621162768\n",
      "epochs =  1 , step =  34000 , current loss_val =  0.7676957451988203\n",
      "epochs =  1 , step =  35000 , current loss_val =  0.9934294011801748\n",
      "epochs =  1 , step =  36000 , current loss_val =  0.980529587008113\n",
      "epochs =  1 , step =  37000 , current loss_val =  2.891341789434466\n",
      "epochs =  1 , step =  38000 , current loss_val =  0.8051966370542356\n",
      "epochs =  2 , step =  0 , current loss_val =  0.7897184295697555\n",
      "epochs =  2 , step =  1000 , current loss_val =  0.8466507202894481\n",
      "epochs =  2 , step =  2000 , current loss_val =  0.7838970075073701\n",
      "epochs =  2 , step =  3000 , current loss_val =  0.8412156205700433\n",
      "epochs =  2 , step =  4000 , current loss_val =  4.812708809452473\n",
      "epochs =  2 , step =  5000 , current loss_val =  0.8979204005702563\n",
      "epochs =  2 , step =  6000 , current loss_val =  0.8561971393012767\n",
      "epochs =  2 , step =  7000 , current loss_val =  1.7328058047004316\n",
      "epochs =  2 , step =  8000 , current loss_val =  0.8548306278790585\n",
      "epochs =  2 , step =  9000 , current loss_val =  0.8112011172394684\n",
      "epochs =  2 , step =  10000 , current loss_val =  0.727153774525346\n",
      "epochs =  2 , step =  11000 , current loss_val =  0.7671108131094099\n",
      "epochs =  2 , step =  12000 , current loss_val =  0.7506217520588573\n",
      "epochs =  2 , step =  13000 , current loss_val =  0.810578396122871\n",
      "epochs =  2 , step =  14000 , current loss_val =  1.090237261567809\n",
      "epochs =  2 , step =  15000 , current loss_val =  0.8091066594688776\n",
      "epochs =  2 , step =  16000 , current loss_val =  0.8297538254575314\n",
      "epochs =  2 , step =  17000 , current loss_val =  0.7579442466172318\n",
      "epochs =  2 , step =  18000 , current loss_val =  0.7654338431305957\n",
      "epochs =  2 , step =  19000 , current loss_val =  0.8045143527129953\n",
      "epochs =  2 , step =  20000 , current loss_val =  0.8272887301823164\n",
      "epochs =  2 , step =  21000 , current loss_val =  0.874958245085717\n",
      "epochs =  2 , step =  22000 , current loss_val =  0.7196209067290678\n",
      "epochs =  2 , step =  23000 , current loss_val =  0.8502060130036699\n",
      "epochs =  2 , step =  24000 , current loss_val =  5.465017243653378\n",
      "epochs =  2 , step =  25000 , current loss_val =  0.8539127533656259\n",
      "epochs =  2 , step =  26000 , current loss_val =  0.7397212738462386\n",
      "epochs =  2 , step =  27000 , current loss_val =  0.8567083774665196\n",
      "epochs =  2 , step =  28000 , current loss_val =  0.9441515150986693\n",
      "epochs =  2 , step =  29000 , current loss_val =  1.0199976570765292\n",
      "epochs =  2 , step =  30000 , current loss_val =  0.8228156265252748\n",
      "epochs =  2 , step =  31000 , current loss_val =  0.8219422500528236\n",
      "epochs =  2 , step =  32000 , current loss_val =  0.8830978623647948\n",
      "epochs =  2 , step =  33000 , current loss_val =  0.7317085608950954\n",
      "epochs =  2 , step =  34000 , current loss_val =  0.8242014471208652\n",
      "epochs =  2 , step =  35000 , current loss_val =  0.9728543017952195\n",
      "epochs =  2 , step =  36000 , current loss_val =  0.9544513906683665\n",
      "epochs =  2 , step =  37000 , current loss_val =  1.9389767496977086\n",
      "epochs =  2 , step =  38000 , current loss_val =  0.8288300824812546\n",
      "epochs =  3 , step =  0 , current loss_val =  0.8127730294417015\n",
      "epochs =  3 , step =  1000 , current loss_val =  0.8685251632685522\n",
      "epochs =  3 , step =  2000 , current loss_val =  0.8249739055015182\n",
      "epochs =  3 , step =  3000 , current loss_val =  0.8668645749143622\n",
      "epochs =  3 , step =  4000 , current loss_val =  2.0676932820195626\n",
      "epochs =  3 , step =  5000 , current loss_val =  0.8781219584495238\n",
      "epochs =  3 , step =  6000 , current loss_val =  0.9520134081807667\n",
      "epochs =  3 , step =  7000 , current loss_val =  1.0341770793507954\n",
      "epochs =  3 , step =  8000 , current loss_val =  0.90374146827588\n",
      "epochs =  3 , step =  9000 , current loss_val =  0.8363593528374653\n",
      "epochs =  3 , step =  10000 , current loss_val =  0.7316894969742209\n",
      "epochs =  3 , step =  11000 , current loss_val =  0.7840546247952737\n",
      "epochs =  3 , step =  12000 , current loss_val =  0.7783339895741092\n",
      "epochs =  3 , step =  13000 , current loss_val =  0.8239261664241796\n",
      "epochs =  3 , step =  14000 , current loss_val =  1.0437875841321405\n",
      "epochs =  3 , step =  15000 , current loss_val =  0.8479253235837259\n",
      "epochs =  3 , step =  16000 , current loss_val =  0.84301079555426\n",
      "epochs =  3 , step =  17000 , current loss_val =  0.8069263303954793\n",
      "epochs =  3 , step =  18000 , current loss_val =  0.7893132339400486\n",
      "epochs =  3 , step =  19000 , current loss_val =  0.8235960782288456\n",
      "epochs =  3 , step =  20000 , current loss_val =  0.8219451550663344\n",
      "epochs =  3 , step =  21000 , current loss_val =  0.8477174310947612\n",
      "epochs =  3 , step =  22000 , current loss_val =  0.7180662055446153\n",
      "epochs =  3 , step =  23000 , current loss_val =  0.8529979843264432\n",
      "epochs =  3 , step =  24000 , current loss_val =  6.06140828866345\n",
      "epochs =  3 , step =  25000 , current loss_val =  0.8802300743334373\n",
      "epochs =  3 , step =  26000 , current loss_val =  0.7401921790508453\n",
      "epochs =  3 , step =  27000 , current loss_val =  0.8853724958076528\n",
      "epochs =  3 , step =  28000 , current loss_val =  0.904147556151426\n",
      "epochs =  3 , step =  29000 , current loss_val =  1.0133175320534131\n",
      "epochs =  3 , step =  30000 , current loss_val =  0.8434792807866038\n",
      "epochs =  3 , step =  31000 , current loss_val =  0.8598753716332984\n",
      "epochs =  3 , step =  32000 , current loss_val =  0.8881600097076421\n",
      "epochs =  3 , step =  33000 , current loss_val =  0.7491741482142175\n",
      "epochs =  3 , step =  34000 , current loss_val =  0.8317585732019919\n",
      "epochs =  3 , step =  35000 , current loss_val =  0.9465133356807702\n",
      "epochs =  3 , step =  36000 , current loss_val =  0.9393925115516321\n",
      "epochs =  3 , step =  37000 , current loss_val =  1.383100687987033\n",
      "epochs =  3 , step =  38000 , current loss_val =  0.8337108032234939\n",
      "epochs =  4 , step =  0 , current loss_val =  0.815816006386445\n",
      "epochs =  4 , step =  1000 , current loss_val =  0.8457057612706662\n",
      "epochs =  4 , step =  2000 , current loss_val =  0.8249495106439426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  4 , step =  3000 , current loss_val =  0.8774988771018198\n",
      "epochs =  4 , step =  4000 , current loss_val =  2.0804824636353394\n",
      "epochs =  4 , step =  5000 , current loss_val =  0.8872295745991164\n",
      "epochs =  4 , step =  6000 , current loss_val =  0.9832953537973697\n",
      "epochs =  4 , step =  7000 , current loss_val =  0.9102528765674057\n",
      "epochs =  4 , step =  8000 , current loss_val =  0.9136538658299099\n",
      "epochs =  4 , step =  9000 , current loss_val =  0.851715129098827\n",
      "epochs =  4 , step =  10000 , current loss_val =  0.7307717269238736\n",
      "epochs =  4 , step =  11000 , current loss_val =  0.8124545805989783\n",
      "epochs =  4 , step =  12000 , current loss_val =  0.7960528190488447\n",
      "epochs =  4 , step =  13000 , current loss_val =  0.839108759996174\n",
      "epochs =  4 , step =  14000 , current loss_val =  1.0002859685808163\n",
      "epochs =  4 , step =  15000 , current loss_val =  0.874237880515416\n",
      "epochs =  4 , step =  16000 , current loss_val =  0.8377872773733146\n",
      "epochs =  4 , step =  17000 , current loss_val =  0.8390526610479037\n",
      "epochs =  4 , step =  18000 , current loss_val =  0.8074395711095699\n",
      "epochs =  4 , step =  19000 , current loss_val =  0.8394789812167621\n",
      "epochs =  4 , step =  20000 , current loss_val =  0.8386342069256781\n",
      "epochs =  4 , step =  21000 , current loss_val =  0.8870169762433018\n",
      "epochs =  4 , step =  22000 , current loss_val =  0.7061890016012978\n",
      "epochs =  4 , step =  23000 , current loss_val =  0.8359584803515482\n",
      "epochs =  4 , step =  24000 , current loss_val =  6.815940715029696\n",
      "epochs =  4 , step =  25000 , current loss_val =  0.8980161046802473\n",
      "epochs =  4 , step =  26000 , current loss_val =  0.733174209416036\n",
      "epochs =  4 , step =  27000 , current loss_val =  0.898352802766262\n",
      "epochs =  4 , step =  28000 , current loss_val =  0.8944927314261901\n",
      "epochs =  4 , step =  29000 , current loss_val =  0.9997941036040919\n",
      "epochs =  4 , step =  30000 , current loss_val =  0.8697755582059864\n",
      "epochs =  4 , step =  31000 , current loss_val =  0.8860579515354811\n",
      "epochs =  4 , step =  32000 , current loss_val =  0.8757856829258039\n",
      "epochs =  4 , step =  33000 , current loss_val =  0.750380671370973\n",
      "epochs =  4 , step =  34000 , current loss_val =  0.836229883257393\n",
      "epochs =  4 , step =  35000 , current loss_val =  0.943170754499949\n",
      "epochs =  4 , step =  36000 , current loss_val =  0.9331978535292365\n",
      "epochs =  4 , step =  37000 , current loss_val =  1.1920562240883794\n",
      "epochs =  4 , step =  38000 , current loss_val =  0.8386002764580994\n",
      "epochs =  5 , step =  0 , current loss_val =  0.8251912912045475\n",
      "epochs =  5 , step =  1000 , current loss_val =  0.8331553119197328\n",
      "epochs =  5 , step =  2000 , current loss_val =  0.8225679007681876\n",
      "epochs =  5 , step =  3000 , current loss_val =  0.8850199576283737\n",
      "epochs =  5 , step =  4000 , current loss_val =  1.3993099681014038\n",
      "epochs =  5 , step =  5000 , current loss_val =  0.8986956071164672\n",
      "epochs =  5 , step =  6000 , current loss_val =  0.9396358471976792\n",
      "epochs =  5 , step =  7000 , current loss_val =  0.8581457944362713\n",
      "epochs =  5 , step =  8000 , current loss_val =  0.925313487364209\n",
      "epochs =  5 , step =  9000 , current loss_val =  0.861322683419484\n",
      "epochs =  5 , step =  10000 , current loss_val =  0.74519822513294\n",
      "epochs =  5 , step =  11000 , current loss_val =  0.8475863193007406\n",
      "epochs =  5 , step =  12000 , current loss_val =  0.8138855545575183\n",
      "epochs =  5 , step =  13000 , current loss_val =  0.8542352042325785\n",
      "epochs =  5 , step =  14000 , current loss_val =  0.9829481661033488\n",
      "epochs =  5 , step =  15000 , current loss_val =  0.8924323008721905\n",
      "epochs =  5 , step =  16000 , current loss_val =  0.8392203668261468\n",
      "epochs =  5 , step =  17000 , current loss_val =  0.8595976121339728\n",
      "epochs =  5 , step =  18000 , current loss_val =  0.823534023360182\n",
      "epochs =  5 , step =  19000 , current loss_val =  0.8481366087377537\n",
      "epochs =  5 , step =  20000 , current loss_val =  0.8543918949662164\n",
      "epochs =  5 , step =  21000 , current loss_val =  0.9455017175874625\n",
      "epochs =  5 , step =  22000 , current loss_val =  0.6908234926461948\n",
      "epochs =  5 , step =  23000 , current loss_val =  0.8234483684423477\n",
      "epochs =  5 , step =  24000 , current loss_val =  6.7078346873244925\n",
      "epochs =  5 , step =  25000 , current loss_val =  0.9166970097351476\n",
      "epochs =  5 , step =  26000 , current loss_val =  0.731270607877495\n",
      "epochs =  5 , step =  27000 , current loss_val =  0.9124209474946581\n",
      "epochs =  5 , step =  28000 , current loss_val =  0.899736476869995\n",
      "epochs =  5 , step =  29000 , current loss_val =  0.9765341156297634\n",
      "epochs =  5 , step =  30000 , current loss_val =  0.8938950704873149\n",
      "epochs =  5 , step =  31000 , current loss_val =  0.8985014567762339\n",
      "epochs =  5 , step =  32000 , current loss_val =  0.8658244393082075\n",
      "epochs =  5 , step =  33000 , current loss_val =  0.746907333470917\n",
      "epochs =  5 , step =  34000 , current loss_val =  0.8478324010272604\n",
      "epochs =  5 , step =  35000 , current loss_val =  0.9402106114752301\n",
      "epochs =  5 , step =  36000 , current loss_val =  0.9400151866508154\n",
      "epochs =  5 , step =  37000 , current loss_val =  1.1234201788669627\n",
      "epochs =  5 , step =  38000 , current loss_val =  0.8478492317134755\n",
      "epochs =  6 , step =  0 , current loss_val =  0.8373024539638171\n",
      "epochs =  6 , step =  1000 , current loss_val =  0.8407236450795368\n",
      "epochs =  6 , step =  2000 , current loss_val =  0.8235535619502476\n",
      "epochs =  6 , step =  3000 , current loss_val =  0.8923368499694715\n",
      "epochs =  6 , step =  4000 , current loss_val =  1.007860839037091\n",
      "epochs =  6 , step =  5000 , current loss_val =  0.9117166701659414\n",
      "epochs =  6 , step =  6000 , current loss_val =  0.8880841013502673\n",
      "epochs =  6 , step =  7000 , current loss_val =  0.859118781141017\n",
      "epochs =  6 , step =  8000 , current loss_val =  0.9365803017691163\n",
      "epochs =  6 , step =  9000 , current loss_val =  0.8733221291614647\n",
      "epochs =  6 , step =  10000 , current loss_val =  0.7652095832701272\n",
      "epochs =  6 , step =  11000 , current loss_val =  0.8695111062082891\n",
      "epochs =  6 , step =  12000 , current loss_val =  0.8307533321121174\n",
      "epochs =  6 , step =  13000 , current loss_val =  0.8669377993760927\n",
      "epochs =  6 , step =  14000 , current loss_val =  0.9771170738992685\n",
      "epochs =  6 , step =  15000 , current loss_val =  0.9070337050178635\n",
      "epochs =  6 , step =  16000 , current loss_val =  0.8488059934076021\n",
      "epochs =  6 , step =  17000 , current loss_val =  0.8724479548282473\n",
      "epochs =  6 , step =  18000 , current loss_val =  0.8370912608568541\n",
      "epochs =  6 , step =  19000 , current loss_val =  0.853737705640196\n",
      "epochs =  6 , step =  20000 , current loss_val =  0.8719850392016208\n",
      "epochs =  6 , step =  21000 , current loss_val =  0.9734228600961694\n",
      "epochs =  6 , step =  22000 , current loss_val =  0.6846928515468421\n",
      "epochs =  6 , step =  23000 , current loss_val =  0.8276242754851196\n",
      "epochs =  6 , step =  24000 , current loss_val =  6.058461931154222\n",
      "epochs =  6 , step =  25000 , current loss_val =  0.931969364983595\n",
      "epochs =  6 , step =  26000 , current loss_val =  0.73361235697374\n",
      "epochs =  6 , step =  27000 , current loss_val =  0.9257445876439098\n",
      "epochs =  6 , step =  28000 , current loss_val =  0.9061070783272999\n",
      "epochs =  6 , step =  29000 , current loss_val =  0.9478811613695424\n",
      "epochs =  6 , step =  30000 , current loss_val =  0.9104200643196738\n",
      "epochs =  6 , step =  31000 , current loss_val =  0.9155187924853875\n",
      "epochs =  6 , step =  32000 , current loss_val =  0.861208025699517\n",
      "epochs =  6 , step =  33000 , current loss_val =  0.7489361874743533\n",
      "epochs =  6 , step =  34000 , current loss_val =  0.8623882060520847\n",
      "epochs =  6 , step =  35000 , current loss_val =  0.9612176383850461\n",
      "epochs =  6 , step =  36000 , current loss_val =  0.9387058211517192\n",
      "epochs =  6 , step =  37000 , current loss_val =  1.1130014193987208\n",
      "epochs =  6 , step =  38000 , current loss_val =  0.8595787763196723\n",
      "epochs =  7 , step =  0 , current loss_val =  0.8545417373013965\n",
      "epochs =  7 , step =  1000 , current loss_val =  0.854150577489565\n",
      "epochs =  7 , step =  2000 , current loss_val =  0.832071077782011\n",
      "epochs =  7 , step =  3000 , current loss_val =  0.9033316234208161\n",
      "epochs =  7 , step =  4000 , current loss_val =  0.9329210505100992\n",
      "epochs =  7 , step =  5000 , current loss_val =  0.9114633740046734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  7 , step =  6000 , current loss_val =  0.8567634240702154\n",
      "epochs =  7 , step =  7000 , current loss_val =  0.8733819611965338\n",
      "epochs =  7 , step =  8000 , current loss_val =  0.9540687426495724\n",
      "epochs =  7 , step =  9000 , current loss_val =  0.8915690102624654\n",
      "epochs =  7 , step =  10000 , current loss_val =  0.7817094378756296\n",
      "epochs =  7 , step =  11000 , current loss_val =  0.8604038986182999\n",
      "epochs =  7 , step =  12000 , current loss_val =  0.8486179036713771\n",
      "epochs =  7 , step =  13000 , current loss_val =  0.884163534313576\n",
      "epochs =  7 , step =  14000 , current loss_val =  0.9733972128983727\n",
      "epochs =  7 , step =  15000 , current loss_val =  0.9243965421920454\n",
      "epochs =  7 , step =  16000 , current loss_val =  0.8616881150020349\n",
      "epochs =  7 , step =  17000 , current loss_val =  0.8826516142530545\n",
      "epochs =  7 , step =  18000 , current loss_val =  0.8552232015519283\n",
      "epochs =  7 , step =  19000 , current loss_val =  0.8638197792412328\n",
      "epochs =  7 , step =  20000 , current loss_val =  0.8912718042305365\n",
      "epochs =  7 , step =  21000 , current loss_val =  0.9700853715320255\n",
      "epochs =  7 , step =  22000 , current loss_val =  0.6839750019779738\n",
      "epochs =  7 , step =  23000 , current loss_val =  0.8399442706393683\n",
      "epochs =  7 , step =  24000 , current loss_val =  5.535869773415787\n",
      "epochs =  7 , step =  25000 , current loss_val =  0.9390255584006242\n",
      "epochs =  7 , step =  26000 , current loss_val =  0.7393320364315331\n",
      "epochs =  7 , step =  27000 , current loss_val =  0.9368153663638628\n",
      "epochs =  7 , step =  28000 , current loss_val =  0.9040545872040726\n",
      "epochs =  7 , step =  29000 , current loss_val =  0.935684906010086\n",
      "epochs =  7 , step =  30000 , current loss_val =  0.930176671553577\n",
      "epochs =  7 , step =  31000 , current loss_val =  0.9377062440510696\n",
      "epochs =  7 , step =  32000 , current loss_val =  0.8637283395635253\n",
      "epochs =  7 , step =  33000 , current loss_val =  0.7552461101840687\n",
      "epochs =  7 , step =  34000 , current loss_val =  0.8745890702604869\n",
      "epochs =  7 , step =  35000 , current loss_val =  0.9747266357037143\n",
      "epochs =  7 , step =  36000 , current loss_val =  0.927471537998577\n",
      "epochs =  7 , step =  37000 , current loss_val =  1.1005404893308286\n",
      "epochs =  7 , step =  38000 , current loss_val =  0.8747013494742406\n",
      "epochs =  8 , step =  0 , current loss_val =  0.8739177703145409\n",
      "epochs =  8 , step =  1000 , current loss_val =  0.8676563724460159\n",
      "epochs =  8 , step =  2000 , current loss_val =  0.8440994380633544\n",
      "epochs =  8 , step =  3000 , current loss_val =  0.916966030590096\n",
      "epochs =  8 , step =  4000 , current loss_val =  0.9406680778382566\n",
      "epochs =  8 , step =  5000 , current loss_val =  0.9073134402221438\n",
      "epochs =  8 , step =  6000 , current loss_val =  0.8281199125577553\n",
      "epochs =  8 , step =  7000 , current loss_val =  0.8879406936359928\n",
      "epochs =  8 , step =  8000 , current loss_val =  0.9741143490751456\n",
      "epochs =  8 , step =  9000 , current loss_val =  0.9054845967052947\n",
      "epochs =  8 , step =  10000 , current loss_val =  0.7957381702141857\n",
      "epochs =  8 , step =  11000 , current loss_val =  0.8515001716838495\n",
      "epochs =  8 , step =  12000 , current loss_val =  0.867651921212073\n",
      "epochs =  8 , step =  13000 , current loss_val =  0.9032655523129203\n",
      "epochs =  8 , step =  14000 , current loss_val =  0.9752913825392254\n",
      "epochs =  8 , step =  15000 , current loss_val =  0.9373606927580969\n",
      "epochs =  8 , step =  16000 , current loss_val =  0.8731721303473554\n",
      "epochs =  8 , step =  17000 , current loss_val =  0.8959444917495295\n",
      "epochs =  8 , step =  18000 , current loss_val =  0.8811462770566538\n",
      "epochs =  8 , step =  19000 , current loss_val =  0.8770507569226393\n",
      "epochs =  8 , step =  20000 , current loss_val =  0.9116229549612193\n",
      "epochs =  8 , step =  21000 , current loss_val =  0.9735478162468081\n",
      "epochs =  8 , step =  22000 , current loss_val =  0.685640221375288\n",
      "epochs =  8 , step =  23000 , current loss_val =  0.8625482545888219\n",
      "epochs =  8 , step =  24000 , current loss_val =  5.308084223516622\n",
      "epochs =  8 , step =  25000 , current loss_val =  0.9449946406146775\n",
      "epochs =  8 , step =  26000 , current loss_val =  0.7420488418758611\n",
      "epochs =  8 , step =  27000 , current loss_val =  0.9465907438784961\n",
      "epochs =  8 , step =  28000 , current loss_val =  0.9014605808149287\n",
      "epochs =  8 , step =  29000 , current loss_val =  0.9309233544398279\n",
      "epochs =  8 , step =  30000 , current loss_val =  0.9419510438124816\n",
      "epochs =  8 , step =  31000 , current loss_val =  0.9578165900374122\n",
      "epochs =  8 , step =  32000 , current loss_val =  0.8688814027352917\n",
      "epochs =  8 , step =  33000 , current loss_val =  0.7601377064287138\n",
      "epochs =  8 , step =  34000 , current loss_val =  0.8879023279293908\n",
      "epochs =  8 , step =  35000 , current loss_val =  0.9627070714164667\n",
      "epochs =  8 , step =  36000 , current loss_val =  0.9257583401868741\n",
      "epochs =  8 , step =  37000 , current loss_val =  1.0860776092276492\n",
      "epochs =  8 , step =  38000 , current loss_val =  0.8878657270826638\n",
      "epochs =  9 , step =  0 , current loss_val =  0.8927420118118266\n",
      "epochs =  9 , step =  1000 , current loss_val =  0.881480117470246\n",
      "epochs =  9 , step =  2000 , current loss_val =  0.8542826590414148\n",
      "epochs =  9 , step =  3000 , current loss_val =  0.9291049550308412\n",
      "epochs =  9 , step =  4000 , current loss_val =  0.9651968116755641\n",
      "epochs =  9 , step =  5000 , current loss_val =  0.9078455504489086\n",
      "epochs =  9 , step =  6000 , current loss_val =  0.8222333539164512\n",
      "epochs =  9 , step =  7000 , current loss_val =  0.8937264937743938\n",
      "epochs =  9 , step =  8000 , current loss_val =  0.9900143298130691\n",
      "epochs =  9 , step =  9000 , current loss_val =  0.9127896503943387\n",
      "epochs =  9 , step =  10000 , current loss_val =  0.808201860922446\n",
      "epochs =  9 , step =  11000 , current loss_val =  0.8520850658070701\n",
      "epochs =  9 , step =  12000 , current loss_val =  0.8855292159256175\n",
      "epochs =  9 , step =  13000 , current loss_val =  0.9184114588950565\n",
      "epochs =  9 , step =  14000 , current loss_val =  0.9789453779771998\n",
      "epochs =  9 , step =  15000 , current loss_val =  0.949841894504087\n",
      "epochs =  9 , step =  16000 , current loss_val =  0.8819936460053973\n",
      "epochs =  9 , step =  17000 , current loss_val =  0.910981346966995\n",
      "epochs =  9 , step =  18000 , current loss_val =  0.9046461272375833\n",
      "epochs =  9 , step =  19000 , current loss_val =  0.888618547879388\n",
      "epochs =  9 , step =  20000 , current loss_val =  0.9292035298560083\n",
      "epochs =  9 , step =  21000 , current loss_val =  0.9850916168971049\n",
      "epochs =  9 , step =  22000 , current loss_val =  0.6906750408867287\n",
      "epochs =  9 , step =  23000 , current loss_val =  0.8889763054769306\n",
      "epochs =  9 , step =  24000 , current loss_val =  5.173488227029097\n",
      "epochs =  9 , step =  25000 , current loss_val =  0.9544032055055044\n",
      "epochs =  9 , step =  26000 , current loss_val =  0.7421442023153281\n",
      "epochs =  9 , step =  27000 , current loss_val =  0.9548619822194508\n",
      "epochs =  9 , step =  28000 , current loss_val =  0.9040444057498996\n",
      "epochs =  9 , step =  29000 , current loss_val =  0.9224481990827273\n",
      "epochs =  9 , step =  30000 , current loss_val =  0.94080192398035\n",
      "epochs =  9 , step =  31000 , current loss_val =  0.9746597943191114\n",
      "epochs =  9 , step =  32000 , current loss_val =  0.8765510338622109\n",
      "epochs =  9 , step =  33000 , current loss_val =  0.7615152111421108\n",
      "epochs =  9 , step =  34000 , current loss_val =  0.9023948788669026\n",
      "epochs =  9 , step =  35000 , current loss_val =  0.9593000091672994\n",
      "epochs =  9 , step =  36000 , current loss_val =  0.9288498192987416\n",
      "epochs =  9 , step =  37000 , current loss_val =  1.0708101310174705\n",
      "epochs =  9 , step =  38000 , current loss_val =  0.901645026017249\n",
      "epochs =  10 , step =  0 , current loss_val =  0.9094190378526921\n",
      "epochs =  10 , step =  1000 , current loss_val =  0.895336307040869\n",
      "epochs =  10 , step =  2000 , current loss_val =  0.8640411708909174\n",
      "epochs =  10 , step =  3000 , current loss_val =  0.9393091501330805\n",
      "epochs =  10 , step =  4000 , current loss_val =  0.9846266181277771\n",
      "epochs =  10 , step =  5000 , current loss_val =  0.9072307022626722\n",
      "epochs =  10 , step =  6000 , current loss_val =  0.8336969924367684\n",
      "epochs =  10 , step =  7000 , current loss_val =  0.8950193532326929\n",
      "epochs =  10 , step =  8000 , current loss_val =  1.003950592785557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  10 , step =  9000 , current loss_val =  0.9199034301768292\n",
      "epochs =  10 , step =  10000 , current loss_val =  0.816593755895807\n",
      "epochs =  10 , step =  11000 , current loss_val =  0.8607517356827655\n",
      "epochs =  10 , step =  12000 , current loss_val =  0.900578739438943\n",
      "epochs =  10 , step =  13000 , current loss_val =  0.9304776098319503\n",
      "epochs =  10 , step =  14000 , current loss_val =  0.9787745865074725\n",
      "epochs =  10 , step =  15000 , current loss_val =  0.9667398577778001\n",
      "epochs =  10 , step =  16000 , current loss_val =  0.8901461284943123\n",
      "epochs =  10 , step =  17000 , current loss_val =  0.9235943709009742\n",
      "epochs =  10 , step =  18000 , current loss_val =  0.9221836071167709\n",
      "epochs =  10 , step =  19000 , current loss_val =  0.8937816698697806\n",
      "epochs =  10 , step =  20000 , current loss_val =  0.9431673462751412\n",
      "epochs =  10 , step =  21000 , current loss_val =  1.0023652565329624\n",
      "epochs =  10 , step =  22000 , current loss_val =  0.6958797401414051\n",
      "epochs =  10 , step =  23000 , current loss_val =  0.9162085742471843\n",
      "epochs =  10 , step =  24000 , current loss_val =  5.032393176086311\n",
      "epochs =  10 , step =  25000 , current loss_val =  0.9671455655169667\n",
      "epochs =  10 , step =  26000 , current loss_val =  0.7418572997474809\n",
      "epochs =  10 , step =  27000 , current loss_val =  0.9605715378686077\n",
      "epochs =  10 , step =  28000 , current loss_val =  0.9136861170644632\n",
      "epochs =  10 , step =  29000 , current loss_val =  0.9176481722462763\n",
      "epochs =  10 , step =  30000 , current loss_val =  0.9389462534663925\n",
      "epochs =  10 , step =  31000 , current loss_val =  0.9920655702667314\n",
      "epochs =  10 , step =  32000 , current loss_val =  0.8866538985981276\n",
      "epochs =  10 , step =  33000 , current loss_val =  0.7605737645243605\n",
      "epochs =  10 , step =  34000 , current loss_val =  0.9103817838106818\n",
      "epochs =  10 , step =  35000 , current loss_val =  0.9657374055304726\n",
      "epochs =  10 , step =  36000 , current loss_val =  0.9351510620090929\n",
      "epochs =  10 , step =  37000 , current loss_val =  1.062862913567487\n",
      "epochs =  10 , step =  38000 , current loss_val =  0.915435533135849\n",
      "epochs =  11 , step =  0 , current loss_val =  0.9230590648643211\n",
      "epochs =  11 , step =  1000 , current loss_val =  0.9096604816909537\n",
      "epochs =  11 , step =  2000 , current loss_val =  0.8720983267575189\n",
      "epochs =  11 , step =  3000 , current loss_val =  0.9462097897527516\n",
      "epochs =  11 , step =  4000 , current loss_val =  1.0023901655067613\n",
      "epochs =  11 , step =  5000 , current loss_val =  0.9040131129266534\n",
      "epochs =  11 , step =  6000 , current loss_val =  0.8559684329445608\n",
      "epochs =  11 , step =  7000 , current loss_val =  0.8960407762212294\n",
      "epochs =  11 , step =  8000 , current loss_val =  1.0176394483626399\n",
      "epochs =  11 , step =  9000 , current loss_val =  0.9256511785729603\n",
      "epochs =  11 , step =  10000 , current loss_val =  0.8250062024536453\n",
      "epochs =  11 , step =  11000 , current loss_val =  0.8719375885636096\n",
      "epochs =  11 , step =  12000 , current loss_val =  0.9129876419928199\n",
      "epochs =  11 , step =  13000 , current loss_val =  0.9453226796016962\n",
      "epochs =  11 , step =  14000 , current loss_val =  0.9742538659797606\n",
      "epochs =  11 , step =  15000 , current loss_val =  0.9824549810984065\n",
      "epochs =  11 , step =  16000 , current loss_val =  0.8982112256619194\n",
      "epochs =  11 , step =  17000 , current loss_val =  0.9330338786332458\n",
      "epochs =  11 , step =  18000 , current loss_val =  0.9348917868836604\n",
      "epochs =  11 , step =  19000 , current loss_val =  0.8978574423283131\n",
      "epochs =  11 , step =  20000 , current loss_val =  0.9553607311180236\n",
      "epochs =  11 , step =  21000 , current loss_val =  1.016417488266688\n",
      "epochs =  11 , step =  22000 , current loss_val =  0.7005646778605992\n",
      "epochs =  11 , step =  23000 , current loss_val =  0.9443134103758277\n",
      "epochs =  11 , step =  24000 , current loss_val =  4.918935866311982\n",
      "epochs =  11 , step =  25000 , current loss_val =  0.9810268119144633\n",
      "epochs =  11 , step =  26000 , current loss_val =  0.7429901896218952\n",
      "epochs =  11 , step =  27000 , current loss_val =  0.9641588082706547\n",
      "epochs =  11 , step =  28000 , current loss_val =  0.9283876158482901\n",
      "epochs =  11 , step =  29000 , current loss_val =  0.9192040777350428\n",
      "epochs =  11 , step =  30000 , current loss_val =  0.9409054989970888\n",
      "epochs =  11 , step =  31000 , current loss_val =  1.0082730393764516\n",
      "epochs =  11 , step =  32000 , current loss_val =  0.8974296839865661\n",
      "epochs =  11 , step =  33000 , current loss_val =  0.7593597610913693\n",
      "epochs =  11 , step =  34000 , current loss_val =  0.9188436644455874\n",
      "epochs =  11 , step =  35000 , current loss_val =  0.980708279120172\n",
      "epochs =  11 , step =  36000 , current loss_val =  0.9441447097742117\n",
      "epochs =  11 , step =  37000 , current loss_val =  1.0613509645211932\n",
      "epochs =  11 , step =  38000 , current loss_val =  0.929567424166853\n",
      "epochs =  12 , step =  0 , current loss_val =  0.9343285217209332\n",
      "epochs =  12 , step =  1000 , current loss_val =  0.9245533997637\n",
      "epochs =  12 , step =  2000 , current loss_val =  0.8782064763617221\n",
      "epochs =  12 , step =  3000 , current loss_val =  0.9507774155475383\n",
      "epochs =  12 , step =  4000 , current loss_val =  1.0064619410048548\n",
      "epochs =  12 , step =  5000 , current loss_val =  0.9026585019028628\n",
      "epochs =  12 , step =  6000 , current loss_val =  0.8773558765531874\n",
      "epochs =  12 , step =  7000 , current loss_val =  0.8944260734415955\n",
      "epochs =  12 , step =  8000 , current loss_val =  1.0296503016491494\n",
      "epochs =  12 , step =  9000 , current loss_val =  0.9290470501052949\n",
      "epochs =  12 , step =  10000 , current loss_val =  0.8338409885347576\n",
      "epochs =  12 , step =  11000 , current loss_val =  0.8804419449062859\n",
      "epochs =  12 , step =  12000 , current loss_val =  0.9220279346223912\n",
      "epochs =  12 , step =  13000 , current loss_val =  0.9616991379502153\n",
      "epochs =  12 , step =  14000 , current loss_val =  0.9609076606553921\n",
      "epochs =  12 , step =  15000 , current loss_val =  0.9958146104246424\n",
      "epochs =  12 , step =  16000 , current loss_val =  0.9051297951322759\n",
      "epochs =  12 , step =  17000 , current loss_val =  0.9385969720672476\n",
      "epochs =  12 , step =  18000 , current loss_val =  0.9450729876426633\n",
      "epochs =  12 , step =  19000 , current loss_val =  0.903414780594348\n",
      "epochs =  12 , step =  20000 , current loss_val =  0.9658992626209086\n",
      "epochs =  12 , step =  21000 , current loss_val =  1.018888671444996\n",
      "epochs =  12 , step =  22000 , current loss_val =  0.7053549439792772\n",
      "epochs =  12 , step =  23000 , current loss_val =  0.9723510415689229\n",
      "epochs =  12 , step =  24000 , current loss_val =  4.817482059395258\n",
      "epochs =  12 , step =  25000 , current loss_val =  0.9944409433811509\n",
      "epochs =  12 , step =  26000 , current loss_val =  0.7469895007423643\n",
      "epochs =  12 , step =  27000 , current loss_val =  0.9672128862902021\n",
      "epochs =  12 , step =  28000 , current loss_val =  0.9462194414094375\n",
      "epochs =  12 , step =  29000 , current loss_val =  0.9259582828687931\n",
      "epochs =  12 , step =  30000 , current loss_val =  0.9446403731904253\n",
      "epochs =  12 , step =  31000 , current loss_val =  1.02095313891782\n",
      "epochs =  12 , step =  32000 , current loss_val =  0.9067980568065903\n",
      "epochs =  12 , step =  33000 , current loss_val =  0.7587406759295534\n",
      "epochs =  12 , step =  34000 , current loss_val =  0.9276016091070711\n",
      "epochs =  12 , step =  35000 , current loss_val =  0.9882720538629965\n",
      "epochs =  12 , step =  36000 , current loss_val =  0.9509154985255311\n",
      "epochs =  12 , step =  37000 , current loss_val =  1.0575138156654513\n",
      "epochs =  12 , step =  38000 , current loss_val =  0.9402605539254387\n",
      "epochs =  13 , step =  0 , current loss_val =  0.944103137134496\n",
      "epochs =  13 , step =  1000 , current loss_val =  0.9371833305268106\n",
      "epochs =  13 , step =  2000 , current loss_val =  0.8853257168485693\n",
      "epochs =  13 , step =  3000 , current loss_val =  0.956640187159103\n",
      "epochs =  13 , step =  4000 , current loss_val =  0.9985843114544787\n",
      "epochs =  13 , step =  5000 , current loss_val =  0.9044335199658264\n",
      "epochs =  13 , step =  6000 , current loss_val =  0.8977597006334648\n",
      "epochs =  13 , step =  7000 , current loss_val =  0.893702847543205\n",
      "epochs =  13 , step =  8000 , current loss_val =  1.0401142131904895\n",
      "epochs =  13 , step =  9000 , current loss_val =  0.9341967138622386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  13 , step =  10000 , current loss_val =  0.8454935947704602\n",
      "epochs =  13 , step =  11000 , current loss_val =  0.884151607513793\n",
      "epochs =  13 , step =  12000 , current loss_val =  0.9289907731959292\n",
      "epochs =  13 , step =  13000 , current loss_val =  0.9762335652559809\n",
      "epochs =  13 , step =  14000 , current loss_val =  0.9463503998322356\n",
      "epochs =  13 , step =  15000 , current loss_val =  1.007911241393133\n",
      "epochs =  13 , step =  16000 , current loss_val =  0.9112278721970987\n",
      "epochs =  13 , step =  17000 , current loss_val =  0.9422910860708709\n",
      "epochs =  13 , step =  18000 , current loss_val =  0.9542272544474157\n",
      "epochs =  13 , step =  19000 , current loss_val =  0.9104514788126686\n",
      "epochs =  13 , step =  20000 , current loss_val =  0.9738277213216019\n",
      "epochs =  13 , step =  21000 , current loss_val =  1.0127781182978253\n",
      "epochs =  13 , step =  22000 , current loss_val =  0.7105306889359054\n",
      "epochs =  13 , step =  23000 , current loss_val =  0.994625206751797\n",
      "epochs =  13 , step =  24000 , current loss_val =  4.70281607010102\n",
      "epochs =  13 , step =  25000 , current loss_val =  1.006245186579087\n",
      "epochs =  13 , step =  26000 , current loss_val =  0.7522706264532115\n",
      "epochs =  13 , step =  27000 , current loss_val =  0.970416386366731\n",
      "epochs =  13 , step =  28000 , current loss_val =  0.9662378347557504\n",
      "epochs =  13 , step =  29000 , current loss_val =  0.9366444973542998\n",
      "epochs =  13 , step =  30000 , current loss_val =  0.947158820756943\n",
      "epochs =  13 , step =  31000 , current loss_val =  1.0290971560531852\n",
      "epochs =  13 , step =  32000 , current loss_val =  0.9136960065638293\n",
      "epochs =  13 , step =  33000 , current loss_val =  0.7592047194635498\n",
      "epochs =  13 , step =  34000 , current loss_val =  0.9359355604688173\n",
      "epochs =  13 , step =  35000 , current loss_val =  0.9920672405468887\n",
      "epochs =  13 , step =  36000 , current loss_val =  0.9564726256437056\n",
      "epochs =  13 , step =  37000 , current loss_val =  1.0513083932383114\n",
      "epochs =  13 , step =  38000 , current loss_val =  0.9487121723947418\n",
      "epochs =  14 , step =  0 , current loss_val =  0.9527425134347592\n",
      "epochs =  14 , step =  1000 , current loss_val =  0.9457419754457741\n",
      "epochs =  14 , step =  2000 , current loss_val =  0.894781233532921\n",
      "epochs =  14 , step =  3000 , current loss_val =  0.9657090831417718\n",
      "epochs =  14 , step =  4000 , current loss_val =  0.9878828422628289\n",
      "epochs =  14 , step =  5000 , current loss_val =  0.9080992482739946\n",
      "epochs =  14 , step =  6000 , current loss_val =  0.9185411229963596\n",
      "epochs =  14 , step =  7000 , current loss_val =  0.8965477083376807\n",
      "epochs =  14 , step =  8000 , current loss_val =  1.049738650743772\n",
      "epochs =  14 , step =  9000 , current loss_val =  0.9411037747550187\n",
      "epochs =  14 , step =  10000 , current loss_val =  0.8600471845456482\n",
      "epochs =  14 , step =  11000 , current loss_val =  0.8848826259428658\n",
      "epochs =  14 , step =  12000 , current loss_val =  0.9355882012769289\n",
      "epochs =  14 , step =  13000 , current loss_val =  0.989147549776187\n",
      "epochs =  14 , step =  14000 , current loss_val =  0.9352233175900888\n",
      "epochs =  14 , step =  15000 , current loss_val =  1.021022484630821\n",
      "epochs =  14 , step =  16000 , current loss_val =  0.918289524903449\n",
      "epochs =  14 , step =  17000 , current loss_val =  0.9456446519012615\n",
      "epochs =  14 , step =  18000 , current loss_val =  0.9628948265729408\n",
      "epochs =  14 , step =  19000 , current loss_val =  0.9165913849965633\n",
      "epochs =  14 , step =  20000 , current loss_val =  0.9809345445680568\n",
      "epochs =  14 , step =  21000 , current loss_val =  1.007510831168388\n",
      "epochs =  14 , step =  22000 , current loss_val =  0.7174987508915778\n",
      "epochs =  14 , step =  23000 , current loss_val =  1.0078449751714729\n",
      "epochs =  14 , step =  24000 , current loss_val =  4.566316812818857\n",
      "epochs =  14 , step =  25000 , current loss_val =  1.016538765544614\n",
      "epochs =  14 , step =  26000 , current loss_val =  0.7567310149163805\n",
      "epochs =  14 , step =  27000 , current loss_val =  0.9725269696154579\n",
      "epochs =  14 , step =  28000 , current loss_val =  0.9875243237573033\n",
      "epochs =  14 , step =  29000 , current loss_val =  0.9496398135488257\n",
      "epochs =  14 , step =  30000 , current loss_val =  0.9489564609288251\n",
      "epochs =  14 , step =  31000 , current loss_val =  1.03489136867476\n",
      "epochs =  14 , step =  32000 , current loss_val =  0.920960455096917\n",
      "epochs =  14 , step =  33000 , current loss_val =  0.7606602313472076\n",
      "epochs =  14 , step =  34000 , current loss_val =  0.9462359825852437\n",
      "epochs =  14 , step =  35000 , current loss_val =  0.9950482676635283\n",
      "epochs =  14 , step =  36000 , current loss_val =  0.9622092255916532\n",
      "epochs =  14 , step =  37000 , current loss_val =  1.04745525414602\n",
      "epochs =  14 , step =  38000 , current loss_val =  0.958963487136234\n",
      "epochs =  15 , step =  0 , current loss_val =  0.9596531557560095\n",
      "epochs =  15 , step =  1000 , current loss_val =  0.9528263051001452\n",
      "epochs =  15 , step =  2000 , current loss_val =  0.903618067154691\n",
      "epochs =  15 , step =  3000 , current loss_val =  0.9761948366478018\n",
      "epochs =  15 , step =  4000 , current loss_val =  0.986397182938427\n",
      "epochs =  15 , step =  5000 , current loss_val =  0.9129925282179198\n",
      "epochs =  15 , step =  6000 , current loss_val =  0.9346369306889716\n",
      "epochs =  15 , step =  7000 , current loss_val =  0.899597409255936\n",
      "epochs =  15 , step =  8000 , current loss_val =  1.0586170296611968\n",
      "epochs =  15 , step =  9000 , current loss_val =  0.9496636394382615\n",
      "epochs =  15 , step =  10000 , current loss_val =  0.874863390024094\n",
      "epochs =  15 , step =  11000 , current loss_val =  0.885992774786255\n",
      "epochs =  15 , step =  12000 , current loss_val =  0.9437093237697701\n",
      "epochs =  15 , step =  13000 , current loss_val =  1.0017633828651533\n",
      "epochs =  15 , step =  14000 , current loss_val =  0.9297043875200274\n",
      "epochs =  15 , step =  15000 , current loss_val =  1.03519639261334\n",
      "epochs =  15 , step =  16000 , current loss_val =  0.9265234026662296\n",
      "epochs =  15 , step =  17000 , current loss_val =  0.9480330306518863\n",
      "epochs =  15 , step =  18000 , current loss_val =  0.9716562971085552\n",
      "epochs =  15 , step =  19000 , current loss_val =  0.9216923718288679\n",
      "epochs =  15 , step =  20000 , current loss_val =  0.9887622266462297\n",
      "epochs =  15 , step =  21000 , current loss_val =  1.0081199249121573\n",
      "epochs =  15 , step =  22000 , current loss_val =  0.7262893097010282\n",
      "epochs =  15 , step =  23000 , current loss_val =  1.0125741945841968\n",
      "epochs =  15 , step =  24000 , current loss_val =  4.310233397623979\n",
      "epochs =  15 , step =  25000 , current loss_val =  1.0245375488679371\n",
      "epochs =  15 , step =  26000 , current loss_val =  0.7603004598365616\n",
      "epochs =  15 , step =  27000 , current loss_val =  0.974391402926998\n",
      "epochs =  15 , step =  28000 , current loss_val =  1.0019762013416689\n",
      "epochs =  15 , step =  29000 , current loss_val =  0.9640363354116263\n",
      "epochs =  15 , step =  30000 , current loss_val =  0.9513708756627347\n",
      "epochs =  15 , step =  31000 , current loss_val =  1.0406473194059682\n",
      "epochs =  15 , step =  32000 , current loss_val =  0.9282812147495675\n",
      "epochs =  15 , step =  33000 , current loss_val =  0.7620531277741647\n",
      "epochs =  15 , step =  34000 , current loss_val =  0.9589271697115983\n",
      "epochs =  15 , step =  35000 , current loss_val =  0.9983144466371952\n",
      "epochs =  15 , step =  36000 , current loss_val =  0.9666238423565332\n",
      "epochs =  15 , step =  37000 , current loss_val =  1.0464723174982427\n",
      "epochs =  15 , step =  38000 , current loss_val =  0.9706730497316595\n",
      "epochs =  16 , step =  0 , current loss_val =  0.9677528984043466\n",
      "epochs =  16 , step =  1000 , current loss_val =  0.9603967277686549\n",
      "epochs =  16 , step =  2000 , current loss_val =  0.9105905624566665\n",
      "epochs =  16 , step =  3000 , current loss_val =  0.9839966710589554\n",
      "epochs =  16 , step =  4000 , current loss_val =  0.9949169294700793\n",
      "epochs =  16 , step =  5000 , current loss_val =  0.9163654418957593\n",
      "epochs =  16 , step =  6000 , current loss_val =  0.9462246336998976\n",
      "epochs =  16 , step =  7000 , current loss_val =  0.9027547736693248\n",
      "epochs =  16 , step =  8000 , current loss_val =  1.0669618987176395\n",
      "epochs =  16 , step =  9000 , current loss_val =  0.9602548898938974\n",
      "epochs =  16 , step =  10000 , current loss_val =  0.8893981489219271\n",
      "epochs =  16 , step =  11000 , current loss_val =  0.8898215384294406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  16 , step =  12000 , current loss_val =  0.9482450101992362\n",
      "epochs =  16 , step =  13000 , current loss_val =  1.013973343303433\n",
      "epochs =  16 , step =  14000 , current loss_val =  0.9297031894300489\n",
      "epochs =  16 , step =  15000 , current loss_val =  1.0501425990677544\n",
      "epochs =  16 , step =  16000 , current loss_val =  0.9343700352968807\n",
      "epochs =  16 , step =  17000 , current loss_val =  0.9502763301215558\n",
      "epochs =  16 , step =  18000 , current loss_val =  0.9807072686918903\n",
      "epochs =  16 , step =  19000 , current loss_val =  0.9253791380344263\n",
      "epochs =  16 , step =  20000 , current loss_val =  0.9979716496224399\n",
      "epochs =  16 , step =  21000 , current loss_val =  1.0162110243786187\n",
      "epochs =  16 , step =  22000 , current loss_val =  0.7364391373522686\n",
      "epochs =  16 , step =  23000 , current loss_val =  1.0074864251297826\n",
      "epochs =  16 , step =  24000 , current loss_val =  3.925530558799144\n",
      "epochs =  16 , step =  25000 , current loss_val =  1.0298611138007039\n",
      "epochs =  16 , step =  26000 , current loss_val =  0.7643713182075182\n",
      "epochs =  16 , step =  27000 , current loss_val =  0.9779881757149588\n",
      "epochs =  16 , step =  28000 , current loss_val =  1.013750769593762\n",
      "epochs =  16 , step =  29000 , current loss_val =  0.9771736103912555\n",
      "epochs =  16 , step =  30000 , current loss_val =  0.954685071862215\n",
      "epochs =  16 , step =  31000 , current loss_val =  1.0440764512337108\n",
      "epochs =  16 , step =  32000 , current loss_val =  0.9349639072282167\n",
      "epochs =  16 , step =  33000 , current loss_val =  0.7641445799476849\n",
      "epochs =  16 , step =  34000 , current loss_val =  0.9719393841629438\n",
      "epochs =  16 , step =  35000 , current loss_val =  1.0020491052497333\n",
      "epochs =  16 , step =  36000 , current loss_val =  0.9706755536709671\n",
      "epochs =  16 , step =  37000 , current loss_val =  1.0442457856823162\n",
      "epochs =  16 , step =  38000 , current loss_val =  0.9815887585257405\n",
      "epochs =  17 , step =  0 , current loss_val =  0.9767263650997988\n",
      "epochs =  17 , step =  1000 , current loss_val =  0.9675991046180593\n",
      "epochs =  17 , step =  2000 , current loss_val =  0.9171306670245823\n",
      "epochs =  17 , step =  3000 , current loss_val =  0.9894433127783511\n",
      "epochs =  17 , step =  4000 , current loss_val =  1.002772545838761\n",
      "epochs =  17 , step =  5000 , current loss_val =  0.9186675328448533\n",
      "epochs =  17 , step =  6000 , current loss_val =  0.9525340739052783\n",
      "epochs =  17 , step =  7000 , current loss_val =  0.9058056852455229\n",
      "epochs =  17 , step =  8000 , current loss_val =  1.074509064798244\n",
      "epochs =  17 , step =  9000 , current loss_val =  0.9734401203225964\n",
      "epochs =  17 , step =  10000 , current loss_val =  0.9030768809228087\n",
      "epochs =  17 , step =  11000 , current loss_val =  0.8962809717077858\n",
      "epochs =  17 , step =  12000 , current loss_val =  0.9508673484550996\n",
      "epochs =  17 , step =  13000 , current loss_val =  1.024288833632738\n",
      "epochs =  17 , step =  14000 , current loss_val =  0.9336370084921944\n",
      "epochs =  17 , step =  15000 , current loss_val =  1.0633051089606067\n",
      "epochs =  17 , step =  16000 , current loss_val =  0.9429691135279767\n",
      "epochs =  17 , step =  17000 , current loss_val =  0.9541191425562329\n",
      "epochs =  17 , step =  18000 , current loss_val =  0.9895981641612935\n",
      "epochs =  17 , step =  19000 , current loss_val =  0.9283975072307368\n",
      "epochs =  17 , step =  20000 , current loss_val =  1.0082615366100938\n",
      "epochs =  17 , step =  21000 , current loss_val =  1.025102679534728\n",
      "epochs =  17 , step =  22000 , current loss_val =  0.746398514470034\n",
      "epochs =  17 , step =  23000 , current loss_val =  0.9934347276095195\n",
      "epochs =  17 , step =  24000 , current loss_val =  3.4789673541203268\n",
      "epochs =  17 , step =  25000 , current loss_val =  1.0364997469976296\n",
      "epochs =  17 , step =  26000 , current loss_val =  0.7701545388061874\n",
      "epochs =  17 , step =  27000 , current loss_val =  0.9835079970427042\n",
      "epochs =  17 , step =  28000 , current loss_val =  1.0235592888863492\n",
      "epochs =  17 , step =  29000 , current loss_val =  0.9873885350286955\n",
      "epochs =  17 , step =  30000 , current loss_val =  0.9591499226574893\n",
      "epochs =  17 , step =  31000 , current loss_val =  1.0493753192414228\n",
      "epochs =  17 , step =  32000 , current loss_val =  0.9431266726455048\n",
      "epochs =  17 , step =  33000 , current loss_val =  0.7668014195991406\n",
      "epochs =  17 , step =  34000 , current loss_val =  0.9849298916009551\n",
      "epochs =  17 , step =  35000 , current loss_val =  1.0073616397266698\n",
      "epochs =  17 , step =  36000 , current loss_val =  0.977461864736362\n",
      "epochs =  17 , step =  37000 , current loss_val =  1.0426941777135657\n",
      "epochs =  17 , step =  38000 , current loss_val =  0.993540158370427\n",
      "epochs =  18 , step =  0 , current loss_val =  0.9838076071672673\n",
      "epochs =  18 , step =  1000 , current loss_val =  0.9753071197423926\n",
      "epochs =  18 , step =  2000 , current loss_val =  0.9228361524941507\n",
      "epochs =  18 , step =  3000 , current loss_val =  0.9942249091719546\n",
      "epochs =  18 , step =  4000 , current loss_val =  1.0092976665862516\n",
      "epochs =  18 , step =  5000 , current loss_val =  0.9210430197913767\n",
      "epochs =  18 , step =  6000 , current loss_val =  0.9559753941057084\n",
      "epochs =  18 , step =  7000 , current loss_val =  0.9084624321694121\n",
      "epochs =  18 , step =  8000 , current loss_val =  1.0816192759653245\n",
      "epochs =  18 , step =  9000 , current loss_val =  0.9880681114470466\n",
      "epochs =  18 , step =  10000 , current loss_val =  0.916377254226912\n",
      "epochs =  18 , step =  11000 , current loss_val =  0.9027259789270414\n",
      "epochs =  18 , step =  12000 , current loss_val =  0.9547393342005729\n",
      "epochs =  18 , step =  13000 , current loss_val =  1.0335255996187316\n",
      "epochs =  18 , step =  14000 , current loss_val =  0.9404074564479304\n",
      "epochs =  18 , step =  15000 , current loss_val =  1.0754930372187954\n",
      "epochs =  18 , step =  16000 , current loss_val =  0.9528751050083341\n",
      "epochs =  18 , step =  17000 , current loss_val =  0.9600167006816611\n",
      "epochs =  18 , step =  18000 , current loss_val =  0.9979673006726728\n",
      "epochs =  18 , step =  19000 , current loss_val =  0.9319006169395452\n",
      "epochs =  18 , step =  20000 , current loss_val =  1.0199925060559025\n",
      "epochs =  18 , step =  21000 , current loss_val =  1.0289826912990436\n",
      "epochs =  18 , step =  22000 , current loss_val =  0.7551060594357222\n",
      "epochs =  18 , step =  23000 , current loss_val =  0.9873726357164575\n",
      "epochs =  18 , step =  24000 , current loss_val =  2.9794579798650704\n",
      "epochs =  18 , step =  25000 , current loss_val =  1.0486903148081725\n",
      "epochs =  18 , step =  26000 , current loss_val =  0.7755792068114613\n",
      "epochs =  18 , step =  27000 , current loss_val =  0.9905562479185077\n",
      "epochs =  18 , step =  28000 , current loss_val =  1.0292449915014203\n",
      "epochs =  18 , step =  29000 , current loss_val =  0.9969803655937408\n",
      "epochs =  18 , step =  30000 , current loss_val =  0.9639873977911794\n",
      "epochs =  18 , step =  31000 , current loss_val =  1.0562308003572387\n",
      "epochs =  18 , step =  32000 , current loss_val =  0.9532231610232959\n",
      "epochs =  18 , step =  33000 , current loss_val =  0.7686300825339925\n",
      "epochs =  18 , step =  34000 , current loss_val =  0.9990711295710395\n",
      "epochs =  18 , step =  35000 , current loss_val =  1.013866033203925\n",
      "epochs =  18 , step =  36000 , current loss_val =  0.9860019703497034\n",
      "epochs =  18 , step =  37000 , current loss_val =  1.0456025194870517\n",
      "epochs =  18 , step =  38000 , current loss_val =  1.004276078521755\n",
      "epochs =  19 , step =  0 , current loss_val =  0.9892113151617632\n",
      "epochs =  19 , step =  1000 , current loss_val =  0.9843813727959544\n",
      "epochs =  19 , step =  2000 , current loss_val =  0.9277578339512824\n",
      "epochs =  19 , step =  3000 , current loss_val =  0.9998082742513652\n",
      "epochs =  19 , step =  4000 , current loss_val =  1.0148643282472576\n",
      "epochs =  19 , step =  5000 , current loss_val =  0.9250482437466401\n",
      "epochs =  19 , step =  6000 , current loss_val =  0.9578710161128863\n",
      "epochs =  19 , step =  7000 , current loss_val =  0.9113675309625018\n",
      "epochs =  19 , step =  8000 , current loss_val =  1.0892924546159592\n",
      "epochs =  19 , step =  9000 , current loss_val =  1.0020223837995716\n",
      "epochs =  19 , step =  10000 , current loss_val =  0.9297789053886631\n",
      "epochs =  19 , step =  11000 , current loss_val =  0.9082690860748373\n",
      "epochs =  19 , step =  12000 , current loss_val =  0.9598540698335958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  19 , step =  13000 , current loss_val =  1.0424872605522304\n",
      "epochs =  19 , step =  14000 , current loss_val =  0.9467467850508596\n",
      "epochs =  19 , step =  15000 , current loss_val =  1.0875815485742022\n",
      "epochs =  19 , step =  16000 , current loss_val =  0.9622303268315984\n",
      "epochs =  19 , step =  17000 , current loss_val =  0.9669204040818778\n",
      "epochs =  19 , step =  18000 , current loss_val =  1.0051358152885794\n",
      "epochs =  19 , step =  19000 , current loss_val =  0.9348802874910425\n",
      "epochs =  19 , step =  20000 , current loss_val =  1.0325643928621193\n",
      "epochs =  19 , step =  21000 , current loss_val =  1.0279000784814123\n",
      "epochs =  19 , step =  22000 , current loss_val =  0.7618002112388316\n",
      "epochs =  19 , step =  23000 , current loss_val =  0.9961980818569638\n",
      "epochs =  19 , step =  24000 , current loss_val =  2.4444137782466053\n",
      "epochs =  19 , step =  25000 , current loss_val =  1.0604731294368503\n",
      "epochs =  19 , step =  26000 , current loss_val =  0.7801192958874551\n",
      "epochs =  19 , step =  27000 , current loss_val =  0.9978480129044875\n",
      "epochs =  19 , step =  28000 , current loss_val =  1.032880061712925\n",
      "epochs =  19 , step =  29000 , current loss_val =  1.0057536290755182\n",
      "epochs =  19 , step =  30000 , current loss_val =  0.9683089211950956\n",
      "epochs =  19 , step =  31000 , current loss_val =  1.0634908021901723\n",
      "epochs =  19 , step =  32000 , current loss_val =  0.9637187070519423\n",
      "epochs =  19 , step =  33000 , current loss_val =  0.7699494405848192\n",
      "epochs =  19 , step =  34000 , current loss_val =  1.0137077103517014\n",
      "epochs =  19 , step =  35000 , current loss_val =  1.0191986452084343\n",
      "epochs =  19 , step =  36000 , current loss_val =  0.9951022034473722\n",
      "epochs =  19 , step =  37000 , current loss_val =  1.0532030822999177\n",
      "epochs =  19 , step =  38000 , current loss_val =  1.0120171790538073\n",
      "epochs =  20 , step =  0 , current loss_val =  0.994561432174006\n",
      "epochs =  20 , step =  1000 , current loss_val =  0.993058449155998\n",
      "epochs =  20 , step =  2000 , current loss_val =  0.9325975090540312\n",
      "epochs =  20 , step =  3000 , current loss_val =  1.0063636669479776\n",
      "epochs =  20 , step =  4000 , current loss_val =  1.0175993992430001\n",
      "epochs =  20 , step =  5000 , current loss_val =  0.9315684695746509\n",
      "epochs =  20 , step =  6000 , current loss_val =  0.9603275836403339\n",
      "epochs =  20 , step =  7000 , current loss_val =  0.915161086242355\n",
      "epochs =  20 , step =  8000 , current loss_val =  1.0980276928910553\n",
      "epochs =  20 , step =  9000 , current loss_val =  1.0139796870970739\n",
      "epochs =  20 , step =  10000 , current loss_val =  0.9418035273552894\n",
      "epochs =  20 , step =  11000 , current loss_val =  0.9131204295178019\n",
      "epochs =  20 , step =  12000 , current loss_val =  0.9658504257573447\n",
      "epochs =  20 , step =  13000 , current loss_val =  1.0500765490149808\n",
      "epochs =  20 , step =  14000 , current loss_val =  0.9493052679909606\n",
      "epochs =  20 , step =  15000 , current loss_val =  1.0974965749327132\n",
      "epochs =  20 , step =  16000 , current loss_val =  0.9717025839974565\n",
      "epochs =  20 , step =  17000 , current loss_val =  0.9753769293276184\n",
      "epochs =  20 , step =  18000 , current loss_val =  1.0124707131529638\n",
      "epochs =  20 , step =  19000 , current loss_val =  0.9379915193985672\n",
      "epochs =  20 , step =  20000 , current loss_val =  1.0454578954146938\n",
      "epochs =  20 , step =  21000 , current loss_val =  1.022333073300219\n",
      "epochs =  20 , step =  22000 , current loss_val =  0.766914457537618\n",
      "epochs =  20 , step =  23000 , current loss_val =  0.9954693852568631\n",
      "epochs =  20 , step =  24000 , current loss_val =  1.943536779760775\n",
      "epochs =  20 , step =  25000 , current loss_val =  1.068045221361285\n",
      "epochs =  20 , step =  26000 , current loss_val =  0.7845160174888092\n",
      "epochs =  20 , step =  27000 , current loss_val =  1.0055506986887544\n",
      "epochs =  20 , step =  28000 , current loss_val =  1.0352869353149878\n",
      "epochs =  20 , step =  29000 , current loss_val =  1.010930514762297\n",
      "epochs =  20 , step =  30000 , current loss_val =  0.972974324014186\n",
      "epochs =  20 , step =  31000 , current loss_val =  1.0704396602979218\n",
      "epochs =  20 , step =  32000 , current loss_val =  0.9739023177462807\n",
      "epochs =  20 , step =  33000 , current loss_val =  0.7719357704322911\n",
      "epochs =  20 , step =  34000 , current loss_val =  1.024999683638407\n",
      "epochs =  20 , step =  35000 , current loss_val =  1.022107109653413\n",
      "epochs =  20 , step =  36000 , current loss_val =  1.003729603681858\n",
      "epochs =  20 , step =  37000 , current loss_val =  1.0629893474395544\n",
      "epochs =  20 , step =  38000 , current loss_val =  1.0175505119775363\n",
      "\n",
      "elapsed time =  0:33:09.712051\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 100     # hidden 1 nodes\n",
    "o_nodes = 10       # output nodes\n",
    "lr = 0.1           # learning rate\n",
    "epochs = 20         # epochs\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성. \n",
    "loss_val_list = []\n",
    "\n",
    "# 정확도 저장 리스트\n",
    "training_accuracy_list = []\n",
    "validation_accuracy_list = []\n",
    "\n",
    "# 객체 생성\n",
    "nn = NeuralNetwork(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "        \n",
    "        # input_data, target_data normalize        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i+1, \", step = \", step,  \", current loss_val = \", nn.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장 per step\n",
    "        loss_val_list.append(nn.loss_val())    \n",
    "        \n",
    "    # 정확도 계산 및 저장 per epochs\n",
    "    (training_accuracy, not_matched_list) = nn.accuracy(training_data[:, 1:], training_data[:, 0])\n",
    "    (validation_accuracy, not_matched_list) = nn.accuracy(validation_data[:, 1:], validation_data[:, 0])\n",
    "        \n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    validation_accuracy_list.append(validation_accuracy)\n",
    "        \n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Training / Validation Accuracy Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.plot(training_accuracy_list, label='training acc')\n",
    "plt.plot(validation_accuracy_list, label='validation acc')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  97.54  %\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    \n",
    "    test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (accuracy_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', np.round(100*accuracy_ret, 3), ' %')\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최대손실값 / 최소손실값 확인 \n",
    "#### 모든 데이터에 대해 손실값을 저장했기 때문에 최대/최소 찾기 위해서는 epoch 별로 분리해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_loss =  20.950886328245165 , max_loss_index =  768373 , min_loss =  0.5947165459494104 , min_loss_index =  7101\n",
      "epochs_num =  19\n",
      "real_max_index =  27373 , real_min_index =  7101\n"
     ]
    }
   ],
   "source": [
    "max_loss = np.max(loss_val_list)\n",
    "min_loss = np.min(loss_val_list)\n",
    "max_loss_index = np.argmax(loss_val_list)\n",
    "min_loss_index = np.argmin(loss_val_list)\n",
    "\n",
    "print(\"max_loss = \", max_loss, \", max_loss_index = \", max_loss_index, \", min_loss = \", min_loss, \", min_loss_index = \", min_loss_index)\n",
    "\n",
    "epochs_num = int(max_loss_index/len(training_data))  # \n",
    "print('epochs_num = ', epochs_num)\n",
    "\n",
    "if max_loss_index > len(training_data):\n",
    "    real_max_loss_index = max_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_max_loss_index = max_loss_index\n",
    "    \n",
    "\n",
    "if min_loss_index > len(training_data):\n",
    "    real_min_loss_index = min_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_min_loss_index = min_loss_index\n",
    "    \n",
    "\n",
    "\n",
    "print('real_max_index = ', real_max_loss_index, ', real_min_index = ', real_min_loss_index)  # real_min_loss_index 다시 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  4\n",
      "prediction =  7\n"
     ]
    }
   ],
   "source": [
    "# check max loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_max_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_max_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_max_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  8\n",
      "prediction =  8\n"
     ]
    }
   ],
   "source": [
    "# check min loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_min_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_min_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_min_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
