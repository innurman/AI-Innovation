{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 를 이용하여선형회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionTest:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, xdata, tdata, learning_rate, iteration_count):            \n",
    "        \n",
    "        self.xdata = xdata\n",
    "        self.tdata = tdata\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1) # 입력 xdata가 이미 행렬이라 가정한 구현\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        print(\"LinearRegressionTest Object is created\")\n",
    "        \n",
    "    \n",
    "    # obtain current W and current b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W, self.b\n",
    "    \n",
    "    \n",
    "    # loss function\n",
    "    def loss_func(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "        \n",
    "    \n",
    "    # display current error value\n",
    "    def error_val(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "    \n",
    "    \n",
    "    # predict method\n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        y = np.dot(test_data, self.W) + self.b\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    # train method\n",
    "    def train(self):\n",
    "    \n",
    "        f = lambda x : self.loss_func()\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        for step in  range(self.iteration_count):  \n",
    "    \n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "    \n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "    \n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val())\n",
    "                \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (50, 4)\n",
      "t_data.ndim =  2 , t_data.shape =  (50, 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    loaded_data = np.loadtxt('./sps.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    x_data = loaded_data[ :, 1:]\n",
    "    t_data = loaded_data[ :, [0]]\n",
    "\n",
    "    # 데이터 차원 및 shape 확인\n",
    "    print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "    print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) \n",
    "\n",
    "except FileNotFoundError as err:\n",
    "    print(str(err))\n",
    "    \n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-3,  반복횟수 20,000번 수행하는 obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "step =  0 error value =  60.604776072341444\n",
      "step =  1000 error value =  0.004047845907167936\n",
      "step =  2000 error value =  0.00048722369128301977\n",
      "step =  3000 error value =  5.864524808192556e-05\n",
      "step =  4000 error value =  7.0589037112171215e-06\n",
      "step =  5000 error value =  8.496531813563435e-07\n",
      "step =  6000 error value =  1.0226949652836696e-07\n",
      "step =  7000 error value =  1.230978727513882e-08\n",
      "step =  8000 error value =  1.4816819081469759e-09\n",
      "step =  9000 error value =  1.7834437166114527e-10\n",
      "step =  10000 error value =  2.1466628382414438e-11\n",
      "step =  11000 error value =  2.583855772566766e-12\n",
      "step =  12000 error value =  3.1100881478795545e-13\n",
      "step =  13000 error value =  3.7434938904037783e-14\n",
      "step =  14000 error value =  4.5059000875171345e-15\n",
      "step =  15000 error value =  5.423579204531311e-16\n",
      "step =  16000 error value =  6.528154409141282e-17\n",
      "step =  17000 error value =  7.857690960008845e-18\n",
      "step =  18000 error value =  9.458002967175832e-19\n",
      "step =  19000 error value =  1.1384228300504383e-19\n",
      "step =  20000 error value =  1.370281435831186e-20\n",
      "\n",
      "Elapsed Time =>  0:00:14.604084\n"
     ]
    }
   ],
   "source": [
    "# LinearRegressionTest 객체를 만들기 위해 4개의 파라미터 필요\n",
    "# 1st : 입력데이터,  2nd : 정답데이터\n",
    "# 3rd : learning rate,  4th : iteration count\n",
    "obj1 = LinearRegressionTest(x_data, t_data, 1e-3, 20001)\n",
    "\n",
    "obj1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.68609189e-11]\n",
      "[7.]\n",
      "[-8.]\n",
      "[8.]\n",
      "[107.]\n",
      "[2079.99999996]\n",
      "[-1303.00000001]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([ [4, 4, 4, 4], [-3, 0, 9, -1], [-7, -9, -2, 8], [1, -2, 3, -2], [19, -12, 0, -76], [2001, -1, 109, 31], [-1, 102, -200 , 1000] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(obj1.predict(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.],\n",
      "       [-1.],\n",
      "       [ 1.],\n",
      "       [-1.]]), array([1.58863405e-10]))\n"
     ]
    }
   ],
   "source": [
    "print(obj1.get_W_b())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
