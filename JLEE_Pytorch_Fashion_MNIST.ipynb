{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JLEE_Pytorch_Fashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNb2O5wVfcmTddHSA9k/PVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/innurman/AI-Innovation/blob/master/JLEE_Pytorch_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue7tMFD8pTMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://aifactory.space/task/detail.do?taskId=T000030"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjWb44uapUWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29c12569-b040-43b6-cfe6-e3012f3cf000"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#batch_size = 256\n",
        "#learning_rate = 0.0002\n",
        "#num_epoch = 10\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "num_epoch = 1000\n",
        "\n",
        "mnist_train = dset.FashionMNIST(\"../\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.FashionMNIST(\"../\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=False)\n",
        "\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Linear,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(784,300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50,10)\n",
        "        )       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = x.view(-1, 784)\n",
        "        out = self.layer(out)\n",
        "        return out\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = Linear().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_arr =[]\n",
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if j % 1000 == 0:\n",
        "            print(loss)\n",
        "            loss_arr.append(loss.cpu().detach().numpy())\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "pred_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image,label in test_loader:\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        output = model.forward(x)\n",
        "        _,output_index = torch.max(output,1)\n",
        "\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == y_).sum().float()\n",
        "        \n",
        "        pred = output_index.to('cpu').numpy()\n",
        "        pred_labels.extend(pred)\n",
        "\n",
        "print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
        "np.savetxt('submit6.txt', pred_labels, fmt='%d')            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "tensor(2.2867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4442, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2574, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3896, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3244, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1740, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1836, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2084, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2542, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2479, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2210, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2208, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1607, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0967, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0896, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1749, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0970, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0554, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2408, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1348, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0381, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0347, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0889, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0492, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1284, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0170, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0210, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0364, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0107, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0275, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0312, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0325, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0262, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0596, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1069, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0266, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0028, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0049, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0243, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0237, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0447, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0090, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0431, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}