{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제 4] 은닉층 3개 오차역전파 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNetwork Class\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes_1 = hidden_nodes_1\n",
    "        self.hidden_nodes_2 = hidden_nodes_2\n",
    "        self.hidden_nodes_3 = hidden_nodes_3\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        ############################### 가중치 / 바이어스 초기화 #############################################\n",
    "        # 2층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes_1) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes_1)\n",
    "        \n",
    "        # 3층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes_1, self.hidden_nodes_2) / np.sqrt(self.hidden_nodes_1/2)\n",
    "        self.b3= np.random.rand(self.hidden_nodes_2)\n",
    "        \n",
    "        # 4층 hidden layer unit \n",
    "        # Xavier/He 방법으로 self.W4 가중치 초기화\n",
    "        self.W4 = np.random.randn(self.hidden_nodes_2, self.hidden_nodes_3) / np.sqrt(self.hidden_nodes_2/2)\n",
    "        self.b4 = np.random.rand(self.hidden_nodes_3)\n",
    "        \n",
    "        # 5층 output layer unit \n",
    "        # Xavier/He 방법으로 self.W4 가중치 초기화\n",
    "        self.W5 = np.random.randn(self.hidden_nodes_3, self.output_nodes) / np.sqrt(self.hidden_nodes_3/2)\n",
    "        self.b5 = np.random.rand(self.output_nodes)\n",
    "                          \n",
    "        ############################### 선형회귀 Z / 출력 A 초기화 ##########################################\n",
    "        # 5층 output layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z5 = np.zeros([1,output_nodes])\n",
    "        self.A5 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 4층 hidden layer 3 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z4 = np.zeros([1,hidden_nodes_3])\n",
    "        self.A4 = np.zeros([1,hidden_nodes_3])\n",
    "        \n",
    "        # 3층 hidden layer 2 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,hidden_nodes_2])\n",
    "        self.A3 = np.zeros([1,hidden_nodes_2])\n",
    "        \n",
    "        # 2층 hidden layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes_1])\n",
    "        self.A2 = np.zeros([1,hidden_nodes_1])\n",
    "        \n",
    "        # 1층 input layer 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        # 5층 가중합 , 출력 계산\n",
    "        self.Z5 = np.dot(self.A4, self.W5) + self.b5\n",
    "        y = self.A5 = sigmoid(self.Z5)        \n",
    "        \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        # 5층 가중합 , 출력 계산\n",
    "        self.Z5 = np.dot(self.A4, self.W5) + self.b5\n",
    "        y = self.A5 = sigmoid(self.Z5)        \n",
    "        \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐\n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        Z4 = np.dot(A3, self.W4) + self.b4\n",
    "        A4 = sigmoid(Z4)\n",
    "        \n",
    "        Z5 = np.dot(A4, self.W5) + self.b5\n",
    "        y = A5 = sigmoid(Z5)\n",
    "        \n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "            \n",
    "    # input_data : 784 개,  target_data : 10개\n",
    "    def train(self, input_data, target_data):  \n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()      \n",
    "        \n",
    "        # 출력층 loss 인 loss_5, 가중치 W5, 바이어스 b5 계산\n",
    "        loss_5 = (self.A5-self.target_data) * self.A5 * (1-self.A5)    \n",
    "\n",
    "        W5_diff = np.dot(self.A4.T, loss_5)\n",
    "        b5_diff = loss_5\n",
    "        \n",
    "        self.W5 = self.W5 - self.learning_rate * W5_diff        \n",
    "        self.b5 = self.b5 - self.learning_rate * b5_diff\n",
    "        \n",
    "        # 은닉층 3 loss 인 loss_4, 가중치 W4, 바이어스 b4 계산\n",
    "        loss_4 = np.dot(loss_5, self.W5.T) * self.A4 * (1-self.A4)    \n",
    "        \n",
    "        W4_diff = np.dot(self.A3.T, loss_4)\n",
    "        b4_diff = loss_4\n",
    "        \n",
    "        self.W4 = self.W4 - self.learning_rate * W4_diff        \n",
    "        self.b4 = self.b4 - self.learning_rate * b4_diff\n",
    "                \n",
    "        # 은닉층 2 loss 인 loss_3, 가중치 W3, 바이어스 b3 계산\n",
    "        loss_3 = np.dot(loss_4, self.W4.T) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        W3_diff = np.dot(self.A2.T, loss_3)\n",
    "        b3_diff = loss_3\n",
    "        \n",
    "        self.W3 = self.W3 - self.learning_rate * W3_diff        \n",
    "        self.b3 = self.b3 - self.learning_rate * b3_diff              \n",
    "        \n",
    "        # 은닉층 1 loss 인 loss_2,  가중치 W2, 바이어스 b2 계산\n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)   \n",
    "        \n",
    "        W2_diff = np.dot(self.A1.T, loss_2)\n",
    "        b2_diff = loss_2\n",
    "                \n",
    "        self.W2 = self.W2 - self.learning_rate * W2_diff\n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * b2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_data[0,0] =  5.0 , len(training_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 training data 읽어옴\n",
    "\n",
    "try:\n",
    "    \n",
    "    training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    print(\"training_data.shape = \", training_data.shape)\n",
    "    print(\"training_data[0,0] = \", training_data[0,0], \", len(training_data[0]) = \", len(training_data[0]))\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 784 X 20 X 20 X 20 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  8.431200682244604\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.382768695667797\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.264922432675478\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.5974743316532987\n",
      "epochs =  0 , step =  4000 ,  loss_val =  3.3514511205545254\n",
      "epochs =  0 , step =  5000 ,  loss_val =  3.0415297400665455\n",
      "epochs =  0 , step =  6000 ,  loss_val =  2.6743809906110165\n",
      "epochs =  0 , step =  7000 ,  loss_val =  3.169885951123589\n",
      "epochs =  0 , step =  8000 ,  loss_val =  2.977585053194304\n",
      "epochs =  0 , step =  9000 ,  loss_val =  2.5195200962656505\n",
      "epochs =  0 , step =  10000 ,  loss_val =  2.46591096696681\n",
      "epochs =  0 , step =  11000 ,  loss_val =  1.4164608190286647\n",
      "epochs =  0 , step =  12000 ,  loss_val =  2.8636427910953715\n",
      "epochs =  0 , step =  13000 ,  loss_val =  2.1813634533853885\n",
      "epochs =  0 , step =  14000 ,  loss_val =  1.0277952789961116\n",
      "epochs =  0 , step =  15000 ,  loss_val =  2.282683674574327\n",
      "epochs =  0 , step =  16000 ,  loss_val =  2.319626335888935\n",
      "epochs =  0 , step =  17000 ,  loss_val =  1.709478165428784\n",
      "epochs =  0 , step =  18000 ,  loss_val =  1.739477087782743\n",
      "epochs =  0 , step =  19000 ,  loss_val =  1.9770271716785972\n",
      "epochs =  0 , step =  20000 ,  loss_val =  1.865566009108956\n",
      "epochs =  0 , step =  21000 ,  loss_val =  1.3135240541766955\n",
      "epochs =  0 , step =  22000 ,  loss_val =  1.1678311330370332\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.9977035987634397\n",
      "epochs =  0 , step =  24000 ,  loss_val =  1.5838738568750697\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.148896419623167\n",
      "epochs =  0 , step =  26000 ,  loss_val =  0.9945638046518906\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.2609837129238752\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.7788805388413318\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.9029679334943649\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.7678390258727079\n",
      "epochs =  0 , step =  31000 ,  loss_val =  3.0396675697516153\n",
      "epochs =  0 , step =  32000 ,  loss_val =  0.9499203681530006\n",
      "epochs =  0 , step =  33000 ,  loss_val =  0.9702885015109715\n",
      "epochs =  0 , step =  34000 ,  loss_val =  0.9834078801368403\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.6885408382867657\n",
      "epochs =  0 , step =  36000 ,  loss_val =  0.9317363611143565\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.8391480346319524\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.8225087007584361\n",
      "epochs =  0 , step =  39000 ,  loss_val =  0.9416053156807503\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.7587961485645772\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.7882374071553486\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.7064315862320353\n",
      "epochs =  0 , step =  43000 ,  loss_val =  2.484845425622547\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.799737495111604\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.8231726354898822\n",
      "epochs =  0 , step =  46000 ,  loss_val =  1.0072035233709378\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.8588231830228668\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.8809200144625499\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.7848902852883017\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.7546979968829177\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.8516397395867251\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.8084454716559817\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.749714063125186\n",
      "epochs =  0 , step =  54000 ,  loss_val =  1.0343362899858988\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.7193033845326707\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.7131377310169641\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.7706403066144949\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.8345030201523047\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.7742881601899743\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.9894125129586622\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.7952982163010817\n",
      "epochs =  1 , step =  2000 ,  loss_val =  0.982930331099527\n",
      "epochs =  1 , step =  3000 ,  loss_val =  1.2919700902495213\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.7481780406563674\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.790205297134075\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7725590345703403\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.7970908285389315\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7797346547912641\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.8037041354494247\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.7389336354743369\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7838206767233552\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.8302224940594618\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.9758799448079003\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.723825906013591\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.7392908776692755\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.754307896981333\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.8396348877840351\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.7780342570673978\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.8547943864350074\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.7137047068522693\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.8105780252655282\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.7504425357417068\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.746049693066117\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.8073927694130866\n",
      "epochs =  1 , step =  25000 ,  loss_val =  0.7927478105630367\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.7367280862792072\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.7432326483145422\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.7297267323865813\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7384316377785768\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.7469209645793697\n",
      "epochs =  1 , step =  31000 ,  loss_val =  0.7922916749616551\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.68604187857878\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.8008276329113134\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.9354876559643261\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7447795626660458\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.8867242658976723\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.7901313273136922\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.6993931510183907\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.796683683075562\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.7432525432734693\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.7491806105775971\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7508450044910974\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.8236678746671852\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.7803959260002051\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.767641956412409\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7788386721220473\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.771940679283498\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.9467376781181261\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.7573646886677616\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.7777618056141501\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7832415572077098\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7942889506650183\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.7128150225592779\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.9181472096230875\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.737066590493301\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7402979398263566\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.766794263518113\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.7751484441823481\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7713490001650966\n",
      "\n",
      "elapsed time =  0:00:35.644842\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 20\n",
    "hidden_nodes_2 = 20\n",
    "hidden_nodes_3 = 20\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 1e-1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  92.27\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', 100*acc_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 784 X 10 X 20 X 10 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  10.778385081214399\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.408243216027067\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.37095294829591\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.564574155159197\n",
      "epochs =  0 , step =  4000 ,  loss_val =  3.316735788554302\n",
      "epochs =  0 , step =  5000 ,  loss_val =  3.173098888821519\n",
      "epochs =  0 , step =  6000 ,  loss_val =  2.7845937899217983\n",
      "epochs =  0 , step =  7000 ,  loss_val =  3.0974395507873633\n",
      "epochs =  0 , step =  8000 ,  loss_val =  1.9021092288920942\n",
      "epochs =  0 , step =  9000 ,  loss_val =  2.3358044295590408\n",
      "epochs =  0 , step =  10000 ,  loss_val =  3.007998174483781\n",
      "epochs =  0 , step =  11000 ,  loss_val =  1.8830062174621616\n",
      "epochs =  0 , step =  12000 ,  loss_val =  3.008656810140917\n",
      "epochs =  0 , step =  13000 ,  loss_val =  2.6069398957639995\n",
      "epochs =  0 , step =  14000 ,  loss_val =  1.5511009660398822\n",
      "epochs =  0 , step =  15000 ,  loss_val =  2.8773584669478964\n",
      "epochs =  0 , step =  16000 ,  loss_val =  2.9958655574483553\n",
      "epochs =  0 , step =  17000 ,  loss_val =  2.821223293223716\n",
      "epochs =  0 , step =  18000 ,  loss_val =  2.259833988693164\n",
      "epochs =  0 , step =  19000 ,  loss_val =  3.170000361926301\n",
      "epochs =  0 , step =  20000 ,  loss_val =  2.4065964040273444\n",
      "epochs =  0 , step =  21000 ,  loss_val =  1.6083336795109688\n",
      "epochs =  0 , step =  22000 ,  loss_val =  2.1769158892981046\n",
      "epochs =  0 , step =  23000 ,  loss_val =  1.1753539494010123\n",
      "epochs =  0 , step =  24000 ,  loss_val =  3.0386646991329034\n",
      "epochs =  0 , step =  25000 ,  loss_val =  4.035711869512392\n",
      "epochs =  0 , step =  26000 ,  loss_val =  1.3963827873352437\n",
      "epochs =  0 , step =  27000 ,  loss_val =  2.150923762922825\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.8416574534997047\n",
      "epochs =  0 , step =  29000 ,  loss_val =  1.0475536310835485\n",
      "epochs =  0 , step =  30000 ,  loss_val =  1.4986616654748126\n",
      "epochs =  0 , step =  31000 ,  loss_val =  2.190898748406249\n",
      "epochs =  0 , step =  32000 ,  loss_val =  2.4970957400874343\n",
      "epochs =  0 , step =  33000 ,  loss_val =  1.7980173406691342\n",
      "epochs =  0 , step =  34000 ,  loss_val =  1.0306523962758962\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.78737930187595\n",
      "epochs =  0 , step =  36000 ,  loss_val =  1.467095074708791\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.9680150169884296\n",
      "epochs =  0 , step =  38000 ,  loss_val =  1.656876655855961\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.6015363273497716\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.8346012163410446\n",
      "epochs =  0 , step =  41000 ,  loss_val =  1.1953458565894155\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.7622101794254005\n",
      "epochs =  0 , step =  43000 ,  loss_val =  1.2115047505284946\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.9866638926604208\n",
      "epochs =  0 , step =  45000 ,  loss_val =  1.1550181895714333\n",
      "epochs =  0 , step =  46000 ,  loss_val =  1.0500846697309203\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.9746397042059319\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.9110494802912886\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.8385369424433718\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.919381625937918\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.7728316694223158\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.7825052605028462\n",
      "epochs =  0 , step =  53000 ,  loss_val =  1.0633280447886233\n",
      "epochs =  0 , step =  54000 ,  loss_val =  1.049795532169855\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.8020445320277836\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.9605942445638674\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.9003556036067072\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.9839882309907115\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.8569837323793407\n",
      "epochs =  1 , step =  0 ,  loss_val =  1.4964469678716605\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.943122909358405\n",
      "epochs =  1 , step =  2000 ,  loss_val =  2.292610579893658\n",
      "epochs =  1 , step =  3000 ,  loss_val =  0.9401017854675459\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.934653280204774\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.9004538110838461\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7603966457647064\n",
      "epochs =  1 , step =  7000 ,  loss_val =  1.7586392636740535\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.9144140343368505\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.7599303593176296\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.83466894879002\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.773140934169706\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.8856025793643831\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.8407490076344033\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.7881254381889006\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.8837126315300117\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.9768594254263234\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.922530110151027\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.8648495707369369\n",
      "epochs =  1 , step =  19000 ,  loss_val =  1.2591826376767437\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.7765133302285492\n",
      "epochs =  1 , step =  21000 ,  loss_val =  1.0060389289932052\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.8607088017059451\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7771114401654357\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.8539484258227354\n",
      "epochs =  1 , step =  25000 ,  loss_val =  1.0876798148606412\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.8824570908350667\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.8965902511799952\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.777616320758969\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.8584281656597418\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.8013628680636264\n",
      "epochs =  1 , step =  31000 ,  loss_val =  1.2455464396532232\n",
      "epochs =  1 , step =  32000 ,  loss_val =  1.0355878067931137\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.8891421350440091\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.8820925796107559\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7696325340390481\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.8750737359560551\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.8585591804754045\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.8963534317687234\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.8756947779661081\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.9120291252915532\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.9620793294701653\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7658917524910612\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.8900553323553582\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.8670072740089074\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.902074943838537\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.8127883162217829\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.8599897667673684\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.9574523432272714\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.8118092480534447\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.7931643819635811\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.8316856831140804\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7880789942051352\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.7911018920288589\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.8635127288026238\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7722981932601914\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7984952092124729\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.8298763962250925\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.8975698914843845\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7719017258091633\n",
      "epochs =  2 , step =  0 ,  loss_val =  0.9118455666504172\n",
      "epochs =  2 , step =  1000 ,  loss_val =  0.8313563744238697\n",
      "epochs =  2 , step =  2000 ,  loss_val =  2.878361507956602\n",
      "epochs =  2 , step =  3000 ,  loss_val =  1.0890386901507467\n",
      "epochs =  2 , step =  4000 ,  loss_val =  0.9116475662978475\n",
      "epochs =  2 , step =  5000 ,  loss_val =  0.8793809220903002\n",
      "epochs =  2 , step =  6000 ,  loss_val =  0.7935168476571349\n",
      "epochs =  2 , step =  7000 ,  loss_val =  1.2483628631047996\n",
      "epochs =  2 , step =  8000 ,  loss_val =  0.8272600835814873\n",
      "epochs =  2 , step =  9000 ,  loss_val =  0.7749822745639636\n",
      "epochs =  2 , step =  10000 ,  loss_val =  0.8150020772614885\n",
      "epochs =  2 , step =  11000 ,  loss_val =  0.7660207615961556\n",
      "epochs =  2 , step =  12000 ,  loss_val =  0.9788620559206933\n",
      "epochs =  2 , step =  13000 ,  loss_val =  0.893305498517516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  2 , step =  14000 ,  loss_val =  0.7951930827894477\n",
      "epochs =  2 , step =  15000 ,  loss_val =  0.7973689298448664\n",
      "epochs =  2 , step =  16000 ,  loss_val =  0.8869049688931765\n",
      "epochs =  2 , step =  17000 ,  loss_val =  0.8504232324373351\n",
      "epochs =  2 , step =  18000 ,  loss_val =  0.8287922960337555\n",
      "epochs =  2 , step =  19000 ,  loss_val =  0.8837664930545086\n",
      "epochs =  2 , step =  20000 ,  loss_val =  0.7624598323234433\n",
      "epochs =  2 , step =  21000 ,  loss_val =  1.0589790966742558\n",
      "epochs =  2 , step =  22000 ,  loss_val =  0.8085068048278632\n",
      "epochs =  2 , step =  23000 ,  loss_val =  0.8559062478554056\n",
      "epochs =  2 , step =  24000 ,  loss_val =  0.8675457292953248\n",
      "epochs =  2 , step =  25000 ,  loss_val =  0.8521968816754706\n",
      "epochs =  2 , step =  26000 ,  loss_val =  0.809945363786235\n",
      "epochs =  2 , step =  27000 ,  loss_val =  0.9490488243406503\n",
      "epochs =  2 , step =  28000 ,  loss_val =  0.8196620464985863\n",
      "epochs =  2 , step =  29000 ,  loss_val =  0.8415827403252578\n",
      "epochs =  2 , step =  30000 ,  loss_val =  0.7777487174988967\n",
      "epochs =  2 , step =  31000 ,  loss_val =  1.1924266384933235\n",
      "epochs =  2 , step =  32000 ,  loss_val =  1.024087285964251\n",
      "epochs =  2 , step =  33000 ,  loss_val =  0.9121920423607942\n",
      "epochs =  2 , step =  34000 ,  loss_val =  0.8523135053537034\n",
      "epochs =  2 , step =  35000 ,  loss_val =  0.8021265417577773\n",
      "epochs =  2 , step =  36000 ,  loss_val =  0.8063487340127997\n",
      "epochs =  2 , step =  37000 ,  loss_val =  0.816049858386467\n",
      "epochs =  2 , step =  38000 ,  loss_val =  0.8341622637629118\n",
      "epochs =  2 , step =  39000 ,  loss_val =  2.4684942040904776\n",
      "epochs =  2 , step =  40000 ,  loss_val =  0.8586147925631084\n",
      "epochs =  2 , step =  41000 ,  loss_val =  0.7837775854657935\n",
      "epochs =  2 , step =  42000 ,  loss_val =  0.7826964322500691\n",
      "epochs =  2 , step =  43000 ,  loss_val =  0.8109949293976787\n",
      "epochs =  2 , step =  44000 ,  loss_val =  0.8026101974572445\n",
      "epochs =  2 , step =  45000 ,  loss_val =  0.7892993211423931\n",
      "epochs =  2 , step =  46000 ,  loss_val =  0.8833407522576722\n",
      "epochs =  2 , step =  47000 ,  loss_val =  0.8226312925514451\n",
      "epochs =  2 , step =  48000 ,  loss_val =  0.8503289182006412\n",
      "epochs =  2 , step =  49000 ,  loss_val =  0.8011090851721995\n",
      "epochs =  2 , step =  50000 ,  loss_val =  0.7673962939340035\n",
      "epochs =  2 , step =  51000 ,  loss_val =  0.8822720242754729\n",
      "epochs =  2 , step =  52000 ,  loss_val =  0.8341471343564925\n",
      "epochs =  2 , step =  53000 ,  loss_val =  0.9061801605818115\n",
      "epochs =  2 , step =  54000 ,  loss_val =  0.9535419642177331\n",
      "epochs =  2 , step =  55000 ,  loss_val =  0.7960585330103671\n",
      "epochs =  2 , step =  56000 ,  loss_val =  0.8148917126687174\n",
      "epochs =  2 , step =  57000 ,  loss_val =  0.8148595635318281\n",
      "epochs =  2 , step =  58000 ,  loss_val =  0.8944792133110456\n",
      "epochs =  2 , step =  59000 ,  loss_val =  0.7733113599983588\n",
      "epochs =  3 , step =  0 ,  loss_val =  1.013119346481869\n",
      "epochs =  3 , step =  1000 ,  loss_val =  0.7967081558934122\n",
      "epochs =  3 , step =  2000 ,  loss_val =  3.6445142070493834\n",
      "epochs =  3 , step =  3000 ,  loss_val =  0.8730556125536053\n",
      "epochs =  3 , step =  4000 ,  loss_val =  0.9042993314522167\n",
      "epochs =  3 , step =  5000 ,  loss_val =  0.8592713512237923\n",
      "epochs =  3 , step =  6000 ,  loss_val =  0.7824377335977014\n",
      "epochs =  3 , step =  7000 ,  loss_val =  0.8250683431859064\n",
      "epochs =  3 , step =  8000 ,  loss_val =  0.7906085669848882\n",
      "epochs =  3 , step =  9000 ,  loss_val =  0.7958247137785328\n",
      "epochs =  3 , step =  10000 ,  loss_val =  0.7962153518288095\n",
      "epochs =  3 , step =  11000 ,  loss_val =  0.7880452048323415\n",
      "epochs =  3 , step =  12000 ,  loss_val =  1.35389000830342\n",
      "epochs =  3 , step =  13000 ,  loss_val =  0.9067523589741794\n",
      "epochs =  3 , step =  14000 ,  loss_val =  0.8065902256284665\n",
      "epochs =  3 , step =  15000 ,  loss_val =  0.7677102321556217\n",
      "epochs =  3 , step =  16000 ,  loss_val =  0.8620013477676444\n",
      "epochs =  3 , step =  17000 ,  loss_val =  0.8019911672190407\n",
      "epochs =  3 , step =  18000 ,  loss_val =  0.8357938160280098\n",
      "epochs =  3 , step =  19000 ,  loss_val =  1.138756259545834\n",
      "epochs =  3 , step =  20000 ,  loss_val =  0.7610045478400854\n",
      "epochs =  3 , step =  21000 ,  loss_val =  0.9068814249928154\n",
      "epochs =  3 , step =  22000 ,  loss_val =  0.7823431606175825\n",
      "epochs =  3 , step =  23000 ,  loss_val =  0.8756961710169836\n",
      "epochs =  3 , step =  24000 ,  loss_val =  0.7754838808012653\n",
      "epochs =  3 , step =  25000 ,  loss_val =  0.9219786529638828\n",
      "epochs =  3 , step =  26000 ,  loss_val =  0.8219818703640909\n",
      "epochs =  3 , step =  27000 ,  loss_val =  0.9119261751438783\n",
      "epochs =  3 , step =  28000 ,  loss_val =  0.8316174917085414\n",
      "epochs =  3 , step =  29000 ,  loss_val =  0.778223629731955\n",
      "epochs =  3 , step =  30000 ,  loss_val =  0.7750328000423687\n",
      "epochs =  3 , step =  31000 ,  loss_val =  1.0715047891245664\n",
      "epochs =  3 , step =  32000 ,  loss_val =  1.0549764464666975\n",
      "epochs =  3 , step =  33000 ,  loss_val =  0.8190105007458275\n",
      "epochs =  3 , step =  34000 ,  loss_val =  0.8184271821968672\n",
      "epochs =  3 , step =  35000 ,  loss_val =  0.8031590598087694\n",
      "epochs =  3 , step =  36000 ,  loss_val =  0.8458228557285049\n",
      "epochs =  3 , step =  37000 ,  loss_val =  0.8055830735419913\n",
      "epochs =  3 , step =  38000 ,  loss_val =  0.8576255880024166\n",
      "epochs =  3 , step =  39000 ,  loss_val =  7.725640994626572\n",
      "epochs =  3 , step =  40000 ,  loss_val =  0.8713689710798624\n",
      "epochs =  3 , step =  41000 ,  loss_val =  0.7702043221765794\n",
      "epochs =  3 , step =  42000 ,  loss_val =  0.7965237394619498\n",
      "epochs =  3 , step =  43000 ,  loss_val =  0.8155417911871496\n",
      "epochs =  3 , step =  44000 ,  loss_val =  0.7897644465611405\n",
      "epochs =  3 , step =  45000 ,  loss_val =  0.796139397396689\n",
      "epochs =  3 , step =  46000 ,  loss_val =  0.8003927132664641\n",
      "epochs =  3 , step =  47000 ,  loss_val =  0.8101225202610312\n",
      "epochs =  3 , step =  48000 ,  loss_val =  0.8088795952351141\n",
      "epochs =  3 , step =  49000 ,  loss_val =  0.7850400669272741\n",
      "epochs =  3 , step =  50000 ,  loss_val =  0.7761672184583547\n",
      "epochs =  3 , step =  51000 ,  loss_val =  0.8883996467358944\n",
      "epochs =  3 , step =  52000 ,  loss_val =  0.7925149994222831\n",
      "epochs =  3 , step =  53000 ,  loss_val =  0.7717051700071863\n",
      "epochs =  3 , step =  54000 ,  loss_val =  0.8348868183612881\n",
      "epochs =  3 , step =  55000 ,  loss_val =  0.8224341134778924\n",
      "epochs =  3 , step =  56000 ,  loss_val =  0.8148317087495798\n",
      "epochs =  3 , step =  57000 ,  loss_val =  0.8127203029952424\n",
      "epochs =  3 , step =  58000 ,  loss_val =  0.920233236832465\n",
      "epochs =  3 , step =  59000 ,  loss_val =  0.7749111094319289\n",
      "epochs =  4 , step =  0 ,  loss_val =  1.0350235553241363\n",
      "epochs =  4 , step =  1000 ,  loss_val =  0.7934232608534683\n",
      "epochs =  4 , step =  2000 ,  loss_val =  4.120353101208703\n",
      "epochs =  4 , step =  3000 ,  loss_val =  0.8441090308664487\n",
      "epochs =  4 , step =  4000 ,  loss_val =  0.9026497922922769\n",
      "epochs =  4 , step =  5000 ,  loss_val =  0.9090022204467559\n",
      "epochs =  4 , step =  6000 ,  loss_val =  0.7845790453287629\n",
      "epochs =  4 , step =  7000 ,  loss_val =  0.8995395131839666\n",
      "epochs =  4 , step =  8000 ,  loss_val =  0.8046346675035883\n",
      "epochs =  4 , step =  9000 ,  loss_val =  0.778225611462125\n",
      "epochs =  4 , step =  10000 ,  loss_val =  0.7830428538348414\n",
      "epochs =  4 , step =  11000 ,  loss_val =  0.7921952870567486\n",
      "epochs =  4 , step =  12000 ,  loss_val =  0.9940504809080408\n",
      "epochs =  4 , step =  13000 ,  loss_val =  0.9380766432534974\n",
      "epochs =  4 , step =  14000 ,  loss_val =  0.8211929790410288\n",
      "epochs =  4 , step =  15000 ,  loss_val =  0.8206421170521689\n",
      "epochs =  4 , step =  16000 ,  loss_val =  0.841152193855589\n",
      "epochs =  4 , step =  17000 ,  loss_val =  0.8956384305380366\n",
      "epochs =  4 , step =  18000 ,  loss_val =  0.8078902407212545\n",
      "epochs =  4 , step =  19000 ,  loss_val =  0.8733226737823381\n",
      "epochs =  4 , step =  20000 ,  loss_val =  0.7891940250352416\n",
      "epochs =  4 , step =  21000 ,  loss_val =  0.9022596908797811\n",
      "epochs =  4 , step =  22000 ,  loss_val =  0.7755025228631152\n",
      "epochs =  4 , step =  23000 ,  loss_val =  0.8698523621604383\n",
      "epochs =  4 , step =  24000 ,  loss_val =  0.7981857909396156\n",
      "epochs =  4 , step =  25000 ,  loss_val =  0.9932321178670718\n",
      "epochs =  4 , step =  26000 ,  loss_val =  0.8070868544767063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  4 , step =  27000 ,  loss_val =  0.9105540119368509\n",
      "epochs =  4 , step =  28000 ,  loss_val =  0.8252078320521992\n",
      "epochs =  4 , step =  29000 ,  loss_val =  0.805208762214278\n",
      "epochs =  4 , step =  30000 ,  loss_val =  0.7666157518907013\n",
      "epochs =  4 , step =  31000 ,  loss_val =  1.0199110820456827\n",
      "epochs =  4 , step =  32000 ,  loss_val =  1.1255222564530476\n",
      "epochs =  4 , step =  33000 ,  loss_val =  0.7890343205136221\n",
      "epochs =  4 , step =  34000 ,  loss_val =  0.830066175376537\n",
      "epochs =  4 , step =  35000 ,  loss_val =  0.8140420681422329\n",
      "epochs =  4 , step =  36000 ,  loss_val =  0.8640420539102736\n",
      "epochs =  4 , step =  37000 ,  loss_val =  0.7896752734674303\n",
      "epochs =  4 , step =  38000 ,  loss_val =  0.8194089156774156\n",
      "epochs =  4 , step =  39000 ,  loss_val =  6.269967682692098\n",
      "epochs =  4 , step =  40000 ,  loss_val =  0.8768217104817292\n",
      "epochs =  4 , step =  41000 ,  loss_val =  0.80206425851308\n",
      "epochs =  4 , step =  42000 ,  loss_val =  0.8238475655954681\n",
      "epochs =  4 , step =  43000 ,  loss_val =  0.8173796210530567\n",
      "epochs =  4 , step =  44000 ,  loss_val =  0.8085583249137116\n",
      "epochs =  4 , step =  45000 ,  loss_val =  0.7799095408215307\n",
      "epochs =  4 , step =  46000 ,  loss_val =  0.8101398163897151\n",
      "epochs =  4 , step =  47000 ,  loss_val =  0.8036269234583319\n",
      "epochs =  4 , step =  48000 ,  loss_val =  0.8213465548609178\n",
      "epochs =  4 , step =  49000 ,  loss_val =  0.7877058620224767\n",
      "epochs =  4 , step =  50000 ,  loss_val =  0.7918665093413205\n",
      "epochs =  4 , step =  51000 ,  loss_val =  0.8813083824185529\n",
      "epochs =  4 , step =  52000 ,  loss_val =  0.7660376050370478\n",
      "epochs =  4 , step =  53000 ,  loss_val =  0.7853940286471657\n",
      "epochs =  4 , step =  54000 ,  loss_val =  0.8639161564919021\n",
      "epochs =  4 , step =  55000 ,  loss_val =  0.8013097846468286\n",
      "epochs =  4 , step =  56000 ,  loss_val =  0.831763161474915\n",
      "epochs =  4 , step =  57000 ,  loss_val =  0.8239078188272168\n",
      "epochs =  4 , step =  58000 ,  loss_val =  0.9604945576213578\n",
      "epochs =  4 , step =  59000 ,  loss_val =  0.7818505730824407\n",
      "\n",
      "elapsed time =  0:01:54.179826\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 10\n",
    "hidden_nodes_2 = 20\n",
    "hidden_nodes_3 = 10\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, hidden_nodes_3, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  93.67999999999999\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', 100*acc_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
