{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제 4] 은닉층 2개 오차역전파 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNetwork Class\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes_1 = hidden_nodes_1\n",
    "        self.hidden_nodes_2 = hidden_nodes_2\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        #self.W2 = np.random.rand(self.input_nodes,self.hidden_nodes)\n",
    "        # Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes_1) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes_1)\n",
    "        \n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes_1, self.hidden_nodes_2) / np.sqrt(self.hidden_nodes_1/2)\n",
    "        self.b3= np.random.rand(self.hidden_nodes_2)\n",
    "        \n",
    "        # 3층 output layer unit\n",
    "        #self.W3 = np.random.rand(self.hidden_nodes, self.output_nodes)\n",
    "        # Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W4 = np.random.randn(self.hidden_nodes_2, self.output_nodes) / np.sqrt(self.hidden_nodes_2/2)\n",
    "        self.b4 = np.random.rand(self.output_nodes)\n",
    "                                \n",
    "        # 4층 output layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z4 = np.zeros([1,output_nodes])\n",
    "        self.A4 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 3층 hidden layer 2 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,hidden_nodes_2])\n",
    "        self.A3 = np.zeros([1,hidden_nodes_2])\n",
    "        \n",
    "        # 2층 hidden layer 가중합 z, 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes_1])\n",
    "        self.A2 = np.zeros([1,hidden_nodes_1])\n",
    "        \n",
    "        # 1층 input layer 출력 a 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        y = self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        #MSE\n",
    "        #return ( np.sum( (self.A4-self.target_data)**2 ) ) / ( len(self.input_data) )\n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 1층 출력 계산, 가중합과 출력은 입력 값과 동일함\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 2층 가중합, 출력 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 3층 가중합, 출력 계산    \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # 4층 가중합 , 출력 계산\n",
    "        self.Z4 = np.dot(self.A3, self.W4) + self.b4\n",
    "        y = self.A4 = sigmoid(self.Z4)\n",
    "        \n",
    "        #MSE\n",
    "        #return ( np.sum( (self.A4-self.target_data)**2 ) ) / ( len(self.input_data) )\n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐\n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        Z4 = np.dot(A3, self.W4) + self.b4\n",
    "        y = A4 = sigmoid(Z4)\n",
    "        \n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "    \n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "            \n",
    "    # input_data : 784 개,  target_data : 10개\n",
    "    def train(self, input_data, target_data):  \n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        \n",
    "        # 출력층 loss 인 loss_4, W4, b4 계산\n",
    "        loss_4 = (self.A4-self.target_data) * self.A4 * (1-self.A4)     \n",
    "        \n",
    "        W4_diff = np.dot(self.A3.T, loss_4)\n",
    "        b4_diff = loss_4\n",
    "        \n",
    "        self.W4 = self.W4 - self.learning_rate * W4_diff        \n",
    "        self.b4 = self.b4 - self.learning_rate * b4_diff\n",
    "                \n",
    "        # 은닉층 2 loss 인 loss_3, W3, b3 계산\n",
    "        loss_3 = np.dot(loss_4, self.W4.T) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        W3_diff = np.dot(self.A2.T, loss_3)\n",
    "        b3_diff = loss_3\n",
    "        \n",
    "        self.W3 = self.W3 - self.learning_rate * W3_diff        \n",
    "        self.b3 = self.b3 - self.learning_rate * b3_diff         \n",
    "        \n",
    "        # 은닉층 1 loss 인 loss_2, W2, b2 계산  \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        W2_diff = np.dot(self.A1.T, loss_2)\n",
    "        b2_diff = loss_2\n",
    "        \n",
    "        self.W2 = self.W2 - self.learning_rate * W2_diff        \n",
    "        self.b2 = self.b2 - self.learning_rate * b2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_data[0,0] =  5.0 , len(training_data[0]) =  785\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 training data 읽어옴\n",
    "\n",
    "try:\n",
    "    \n",
    "    training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    print(\"training_data.shape = \", training_data.shape)\n",
    "    print(\"training_data[0,0] = \", training_data[0,0], \", len(training_data[0]) = \", len(training_data[0]))\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 784 X 30 X 20 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  8.564689764083967\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.24117147692315\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.379551725998059\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.775318302970159\n",
      "epochs =  0 , step =  4000 ,  loss_val =  2.6708777263704753\n",
      "epochs =  0 , step =  5000 ,  loss_val =  1.8197282358707807\n",
      "epochs =  0 , step =  6000 ,  loss_val =  1.206203256148244\n",
      "epochs =  0 , step =  7000 ,  loss_val =  2.2699108483852037\n",
      "epochs =  0 , step =  8000 ,  loss_val =  0.945958768728595\n",
      "epochs =  0 , step =  9000 ,  loss_val =  1.3130330122271803\n",
      "epochs =  0 , step =  10000 ,  loss_val =  0.9174772911387616\n",
      "epochs =  0 , step =  11000 ,  loss_val =  0.9301654647906228\n",
      "epochs =  0 , step =  12000 ,  loss_val =  1.285427709800529\n",
      "epochs =  0 , step =  13000 ,  loss_val =  1.1500843164478054\n",
      "epochs =  0 , step =  14000 ,  loss_val =  0.6923268410966206\n",
      "epochs =  0 , step =  15000 ,  loss_val =  1.3007946980044574\n",
      "epochs =  0 , step =  16000 ,  loss_val =  0.845876987540336\n",
      "epochs =  0 , step =  17000 ,  loss_val =  1.0080105241212922\n",
      "epochs =  0 , step =  18000 ,  loss_val =  1.1862088613732225\n",
      "epochs =  0 , step =  19000 ,  loss_val =  1.0410808939683747\n",
      "epochs =  0 , step =  20000 ,  loss_val =  0.8492778922819878\n",
      "epochs =  0 , step =  21000 ,  loss_val =  1.0131139372482731\n",
      "epochs =  0 , step =  22000 ,  loss_val =  0.8669669838158478\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.6806862445492086\n",
      "epochs =  0 , step =  24000 ,  loss_val =  0.7219781827189442\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.1064581677918697\n",
      "epochs =  0 , step =  26000 ,  loss_val =  0.7763937421829508\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.1972002320459327\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.6881583946665698\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.7543175442362156\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.6592382406719008\n",
      "epochs =  0 , step =  31000 ,  loss_val =  1.9243507650123441\n",
      "epochs =  0 , step =  32000 ,  loss_val =  0.6588717692369499\n",
      "epochs =  0 , step =  33000 ,  loss_val =  1.0296395079211622\n",
      "epochs =  0 , step =  34000 ,  loss_val =  0.9792482071429676\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.6579985577618932\n",
      "epochs =  0 , step =  36000 ,  loss_val =  0.8872434934296641\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.7394616678635407\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.6456568162911056\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.1376592012332847\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.6573144595203966\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.76125820911803\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.6625494971501656\n",
      "epochs =  0 , step =  43000 ,  loss_val =  1.2026504864773682\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.7348037808339374\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.7614902183574082\n",
      "epochs =  0 , step =  46000 ,  loss_val =  0.7996400326626606\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.7544151102772051\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.841742449905738\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.7090292748617806\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.8241765348511473\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.695850534997504\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.7418571970201944\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.6652659697821306\n",
      "epochs =  0 , step =  54000 ,  loss_val =  0.903869102369345\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.6981507620623911\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.6965952996822402\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.7462158143121245\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.8321097255765901\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.8029951308185568\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.8802226816351482\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.735169755482518\n",
      "epochs =  1 , step =  2000 ,  loss_val =  2.775672939071135\n",
      "epochs =  1 , step =  3000 ,  loss_val =  0.914383018322123\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.7392290901371489\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.7146190796380478\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7039252972615672\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.7717285211170453\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.7360490218734528\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.7382024798714855\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.6979405557810539\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7063952013683105\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.9575109233868165\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.7442350477564148\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.6560027446895135\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.7899904109029325\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.6410348700042618\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.7665151069579516\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.701761245860544\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.6879892477803872\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.6710601474406506\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.8514399084745645\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.8262439555184226\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7076614750900173\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.633305615585861\n",
      "epochs =  1 , step =  25000 ,  loss_val =  1.0424121785055502\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.6867184177709138\n",
      "epochs =  1 , step =  27000 ,  loss_val =  1.0967546313068315\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.6594978521982117\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7459401896778518\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.7058260349885537\n",
      "epochs =  1 , step =  31000 ,  loss_val =  0.9858268823421852\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.6308659309342688\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.884756222023763\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.787333193987849\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.6799221758313332\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.7851791763303339\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.6658468649399366\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.6237929360161816\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.9577503523419724\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.7032523937228546\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.732290684507699\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.6861454569776448\n",
      "epochs =  1 , step =  43000 ,  loss_val =  1.0485697293290481\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.7519708904090172\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.763787637395114\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7623167340336495\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.7347393858999351\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.7358836304090093\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.6835655383041109\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.8083339800088\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.7877373833611945\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.7248900475281422\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.6488929606023961\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.7547586137569086\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7062655327665162\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7072083779015205\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.7466896126021371\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.9139873482287961\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7550041408769392\n",
      "\n",
      "elapsed time =  0:00:45.722776\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 30\n",
    "hidden_nodes_2 = 20\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  93.58\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', 100*acc_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 784 X 40 X 40 X 10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 ,  loss_val =  11.37364336921664\n",
      "epochs =  0 , step =  1000 ,  loss_val =  3.1209096533375584\n",
      "epochs =  0 , step =  2000 ,  loss_val =  3.1599753476383303\n",
      "epochs =  0 , step =  3000 ,  loss_val =  3.5179254514092353\n",
      "epochs =  0 , step =  4000 ,  loss_val =  1.8405294678634703\n",
      "epochs =  0 , step =  5000 ,  loss_val =  1.286411728959947\n",
      "epochs =  0 , step =  6000 ,  loss_val =  1.0087927039234454\n",
      "epochs =  0 , step =  7000 ,  loss_val =  1.947120410954809\n",
      "epochs =  0 , step =  8000 ,  loss_val =  0.7746781628643669\n",
      "epochs =  0 , step =  9000 ,  loss_val =  1.1394699961014016\n",
      "epochs =  0 , step =  10000 ,  loss_val =  0.7900309269569629\n",
      "epochs =  0 , step =  11000 ,  loss_val =  0.7745870585040694\n",
      "epochs =  0 , step =  12000 ,  loss_val =  0.9586291910462993\n",
      "epochs =  0 , step =  13000 ,  loss_val =  0.975649787691054\n",
      "epochs =  0 , step =  14000 ,  loss_val =  0.7099317421594491\n",
      "epochs =  0 , step =  15000 ,  loss_val =  1.0079426547144976\n",
      "epochs =  0 , step =  16000 ,  loss_val =  0.6976714574223171\n",
      "epochs =  0 , step =  17000 ,  loss_val =  0.9006116762217937\n",
      "epochs =  0 , step =  18000 ,  loss_val =  0.9751105977421327\n",
      "epochs =  0 , step =  19000 ,  loss_val =  0.9256473277258362\n",
      "epochs =  0 , step =  20000 ,  loss_val =  0.6786073485511742\n",
      "epochs =  0 , step =  21000 ,  loss_val =  0.9244170480810829\n",
      "epochs =  0 , step =  22000 ,  loss_val =  0.8502453795257612\n",
      "epochs =  0 , step =  23000 ,  loss_val =  0.6914657841263685\n",
      "epochs =  0 , step =  24000 ,  loss_val =  0.7129021600223119\n",
      "epochs =  0 , step =  25000 ,  loss_val =  1.290759925131155\n",
      "epochs =  0 , step =  26000 ,  loss_val =  0.6555092852205426\n",
      "epochs =  0 , step =  27000 ,  loss_val =  1.2300764759802219\n",
      "epochs =  0 , step =  28000 ,  loss_val =  0.6886942568842845\n",
      "epochs =  0 , step =  29000 ,  loss_val =  0.6708721230382725\n",
      "epochs =  0 , step =  30000 ,  loss_val =  0.6503520204851142\n",
      "epochs =  0 , step =  31000 ,  loss_val =  1.7321262436964309\n",
      "epochs =  0 , step =  32000 ,  loss_val =  0.6374435707352291\n",
      "epochs =  0 , step =  33000 ,  loss_val =  1.0373179049105687\n",
      "epochs =  0 , step =  34000 ,  loss_val =  0.8419634094467752\n",
      "epochs =  0 , step =  35000 ,  loss_val =  0.6876852666710952\n",
      "epochs =  0 , step =  36000 ,  loss_val =  0.8666223343129299\n",
      "epochs =  0 , step =  37000 ,  loss_val =  0.6651581606752802\n",
      "epochs =  0 , step =  38000 ,  loss_val =  0.6780646786840869\n",
      "epochs =  0 , step =  39000 ,  loss_val =  1.0295920817644426\n",
      "epochs =  0 , step =  40000 ,  loss_val =  0.6877250710913457\n",
      "epochs =  0 , step =  41000 ,  loss_val =  0.7482244381079421\n",
      "epochs =  0 , step =  42000 ,  loss_val =  0.6960816439559209\n",
      "epochs =  0 , step =  43000 ,  loss_val =  1.9075942267363195\n",
      "epochs =  0 , step =  44000 ,  loss_val =  0.6531633859911865\n",
      "epochs =  0 , step =  45000 ,  loss_val =  0.730304429119265\n",
      "epochs =  0 , step =  46000 ,  loss_val =  0.7563468337228377\n",
      "epochs =  0 , step =  47000 ,  loss_val =  0.6609487509783994\n",
      "epochs =  0 , step =  48000 ,  loss_val =  0.7436587697829493\n",
      "epochs =  0 , step =  49000 ,  loss_val =  0.7422785708694536\n",
      "epochs =  0 , step =  50000 ,  loss_val =  0.8042879238737236\n",
      "epochs =  0 , step =  51000 ,  loss_val =  0.7576380806440275\n",
      "epochs =  0 , step =  52000 ,  loss_val =  0.8187858371583617\n",
      "epochs =  0 , step =  53000 ,  loss_val =  0.6373579888009885\n",
      "epochs =  0 , step =  54000 ,  loss_val =  0.8442819359733068\n",
      "epochs =  0 , step =  55000 ,  loss_val =  0.7034383275327266\n",
      "epochs =  0 , step =  56000 ,  loss_val =  0.7513284008661039\n",
      "epochs =  0 , step =  57000 ,  loss_val =  0.6855188463454753\n",
      "epochs =  0 , step =  58000 ,  loss_val =  0.6826153064860604\n",
      "epochs =  0 , step =  59000 ,  loss_val =  0.7588448756664503\n",
      "epochs =  1 , step =  0 ,  loss_val =  0.8892975658086201\n",
      "epochs =  1 , step =  1000 ,  loss_val =  0.6717940254775187\n",
      "epochs =  1 , step =  2000 ,  loss_val =  1.2645711967108397\n",
      "epochs =  1 , step =  3000 ,  loss_val =  0.8225761681665732\n",
      "epochs =  1 , step =  4000 ,  loss_val =  0.764897532391505\n",
      "epochs =  1 , step =  5000 ,  loss_val =  0.8242270599700218\n",
      "epochs =  1 , step =  6000 ,  loss_val =  0.7086780226014303\n",
      "epochs =  1 , step =  7000 ,  loss_val =  0.7781502220329986\n",
      "epochs =  1 , step =  8000 ,  loss_val =  0.6783823219292937\n",
      "epochs =  1 , step =  9000 ,  loss_val =  0.8202816937989019\n",
      "epochs =  1 , step =  10000 ,  loss_val =  0.7081358550253153\n",
      "epochs =  1 , step =  11000 ,  loss_val =  0.7083406796451724\n",
      "epochs =  1 , step =  12000 ,  loss_val =  0.9317385598564846\n",
      "epochs =  1 , step =  13000 ,  loss_val =  0.8252253599585126\n",
      "epochs =  1 , step =  14000 ,  loss_val =  0.7221653350697529\n",
      "epochs =  1 , step =  15000 ,  loss_val =  0.6772971060272945\n",
      "epochs =  1 , step =  16000 ,  loss_val =  0.6651582267516332\n",
      "epochs =  1 , step =  17000 ,  loss_val =  0.6981480987688895\n",
      "epochs =  1 , step =  18000 ,  loss_val =  0.7562235543696366\n",
      "epochs =  1 , step =  19000 ,  loss_val =  0.8576301875330734\n",
      "epochs =  1 , step =  20000 ,  loss_val =  0.6502369306845119\n",
      "epochs =  1 , step =  21000 ,  loss_val =  0.9204249718667509\n",
      "epochs =  1 , step =  22000 ,  loss_val =  0.7488544682038104\n",
      "epochs =  1 , step =  23000 ,  loss_val =  0.7623211153199134\n",
      "epochs =  1 , step =  24000 ,  loss_val =  0.6839780940075699\n",
      "epochs =  1 , step =  25000 ,  loss_val =  1.0431125255289302\n",
      "epochs =  1 , step =  26000 ,  loss_val =  0.6982751176020529\n",
      "epochs =  1 , step =  27000 ,  loss_val =  0.7845454343094735\n",
      "epochs =  1 , step =  28000 ,  loss_val =  0.7177981475872429\n",
      "epochs =  1 , step =  29000 ,  loss_val =  0.7031374332565336\n",
      "epochs =  1 , step =  30000 ,  loss_val =  0.7074986768249212\n",
      "epochs =  1 , step =  31000 ,  loss_val =  1.0136735796419805\n",
      "epochs =  1 , step =  32000 ,  loss_val =  0.6570130723288654\n",
      "epochs =  1 , step =  33000 ,  loss_val =  0.8832635052594912\n",
      "epochs =  1 , step =  34000 ,  loss_val =  0.7439150845009022\n",
      "epochs =  1 , step =  35000 ,  loss_val =  0.7416066920709744\n",
      "epochs =  1 , step =  36000 ,  loss_val =  0.8517751446201929\n",
      "epochs =  1 , step =  37000 ,  loss_val =  0.7202414437341351\n",
      "epochs =  1 , step =  38000 ,  loss_val =  0.6663365998751282\n",
      "epochs =  1 , step =  39000 ,  loss_val =  0.8183314523447005\n",
      "epochs =  1 , step =  40000 ,  loss_val =  0.7570808012378483\n",
      "epochs =  1 , step =  41000 ,  loss_val =  0.8064717509417357\n",
      "epochs =  1 , step =  42000 ,  loss_val =  0.7391879770556434\n",
      "epochs =  1 , step =  43000 ,  loss_val =  0.8798778841947393\n",
      "epochs =  1 , step =  44000 ,  loss_val =  0.6576691236241852\n",
      "epochs =  1 , step =  45000 ,  loss_val =  0.7172751077470582\n",
      "epochs =  1 , step =  46000 ,  loss_val =  0.7660732140561178\n",
      "epochs =  1 , step =  47000 ,  loss_val =  0.6789797320291867\n",
      "epochs =  1 , step =  48000 ,  loss_val =  0.7661160576292473\n",
      "epochs =  1 , step =  49000 ,  loss_val =  0.7369799656451944\n",
      "epochs =  1 , step =  50000 ,  loss_val =  0.7796648901124315\n",
      "epochs =  1 , step =  51000 ,  loss_val =  0.81583862262898\n",
      "epochs =  1 , step =  52000 ,  loss_val =  0.6976387896988079\n",
      "epochs =  1 , step =  53000 ,  loss_val =  0.6401717823860231\n",
      "epochs =  1 , step =  54000 ,  loss_val =  0.710118994669792\n",
      "epochs =  1 , step =  55000 ,  loss_val =  0.7161480651672442\n",
      "epochs =  1 , step =  56000 ,  loss_val =  0.7623314599870514\n",
      "epochs =  1 , step =  57000 ,  loss_val =  0.7078849648410164\n",
      "epochs =  1 , step =  58000 ,  loss_val =  0.6795647301743954\n",
      "epochs =  1 , step =  59000 ,  loss_val =  0.7815572027740502\n",
      "\n",
      "elapsed time =  0:01:04.065797\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "\n",
    "hidden_nodes_1 = 40\n",
    "hidden_nodes_2 = 40\n",
    "\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 2\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes_1, hidden_nodes_2, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        #target_data = training_data[step, 0]\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        #input_data = training_data[step, 1:]\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \",  loss_val = \", nn.loss_val())\n",
    "        \n",
    "end_time = datetime.now() \n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "test_data[0,0] =  7.0 , len(test_data[0]) =  785\n",
      "Accuracy =  94.38\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (acc_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', 100*acc_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
